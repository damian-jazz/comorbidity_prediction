{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.utils import load_data, remove_zero_features, load_confounders, deconfound_linear, standardize, label_freq_sorted\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier, ClassifierChain\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, brier_score_loss, f1_score, hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_path = 'plots/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of physical cores: 8\n"
     ]
    }
   ],
   "source": [
    "N_CORES = joblib.cpu_count(only_physical_cores=True)\n",
    "print(f\"Number of physical cores: {N_CORES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for classification task\n",
    "subject_data, features, diagnoses = load_data('classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove zero features\n",
    "F = remove_zero_features(features.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load confounders\n",
    "C = load_confounders(subject_data)\n",
    "\n",
    "# Apply deconfounding\n",
    "#F = deconfound_linear(C, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 2815\n",
      "Number of features: 922\n"
     ]
    }
   ],
   "source": [
    "# Standardize\n",
    "X = standardize(F)\n",
    "print(f\"Number of samples: {X.shape[0]}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 13\n"
     ]
    }
   ],
   "source": [
    "# Remove ID column\n",
    "Y = diagnoses.iloc[:,1:]\n",
    "print(f\"Number of labels: {Y.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training set: 2111\n",
      "Number of samples in test set: 704\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into train and test (holdout) set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=0)\n",
    "print(f\"Number of samples in training set: {len(X_train)}\")\n",
    "print(f\"Number of samples in test set: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MultiOutputClassifier\n",
    "Evaluate classification models wrapped in meta estimator MultiOutputClassifier with respect to multi-label performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Always zero baseline estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores for always zero baseline with MultiOutputClassifier with 95% confidence intervals:\n",
      "    AUPRC macro: 0.17 [0.16, 0.18]\n",
      "    AUROC macro: 0.50 [0.50, 0.50]\n",
      "    Brier score: 0.17 [0.16, 0.18]\n",
      "    Hamming loss: 0.17 [0.16, 0.18]\n",
      "    Micro Avg F1 score: 0.00 [0.00, 0.00]\n"
     ]
    }
   ],
   "source": [
    "auprc_zero_basline = []\n",
    "auroc_zero_basline = []\n",
    "brier_zero_basline = []\n",
    "hamm_zero_basline = []\n",
    "f1_zero_basline = []\n",
    "\n",
    "zero_baseline_clf = DummyClassifier(strategy='constant', constant=0 ,random_state=0)\n",
    "zero_baseline_meta_clf = MultiOutputClassifier(zero_baseline_clf)\n",
    "zero_baseline_meta_clf = zero_baseline_meta_clf.fit(X_train, Y_train)\n",
    "\n",
    "for i in range(100):\n",
    "    X_test_resampled, y_test_resampled = resample(X_test, Y_test, replace=True, n_samples=len(Y_test), random_state=0+i)\n",
    "\n",
    "    y_prob = zero_baseline_meta_clf.predict_proba(X_test_resampled)\n",
    "    y_pred = zero_baseline_meta_clf.predict(X_test_resampled)\n",
    "\n",
    "    # Combine prediction probas into single ndarray\n",
    "    y_prob_combined = y_prob[0][:,1].reshape(-1,1)\n",
    "    for i in range(len(y_prob)):\n",
    "        if i == (len(y_prob))-1:\n",
    "            break\n",
    "        else:\n",
    "            y_prob_combined = np.concatenate([y_prob_combined, y_prob[i+1][:,1].reshape(-1,1)], axis=1)\n",
    "\n",
    "    # Compute brier score\n",
    "    brier_scores = np.zeros(len(y_prob))\n",
    "    for i in range(len(y_prob)):\n",
    "        brier_scores[i] = brier_score_loss(y_test_resampled.iloc[:,i], y_prob[i][:,1])\n",
    "    brier_zero_basline.append(brier_scores.mean()) \n",
    "    \n",
    "    # Other metrics\n",
    "    auprc_zero_basline.append(average_precision_score(y_test_resampled, y_prob_combined, average='macro')) \n",
    "    auroc_zero_basline.append(roc_auc_score(y_test_resampled, y_prob_combined, average='macro'))\n",
    "    f1_zero_basline.append(f1_score(y_test_resampled, y_pred, average='micro'))\n",
    "    hamm_zero_basline.append(hamming_loss(y_test_resampled, y_pred))\n",
    "\n",
    "print(f\"Mean scores for always zero baseline with MultiOutputClassifier with 95% confidence intervals:\")\n",
    "print(\"    AUPRC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auprc_zero_basline), np.percentile(auprc_zero_basline, 2.5), np.percentile(auprc_zero_basline, 97.5)))\n",
    "print(\"    AUROC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auroc_zero_basline), np.percentile(auroc_zero_basline, 2.5), np.percentile(auroc_zero_basline, 97.5)))\n",
    "print(\"    Brier score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(brier_zero_basline), np.percentile(brier_zero_basline, 2.5), np.percentile(brier_zero_basline, 97.5)))\n",
    "print(\"    Hamming loss: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(hamm_zero_basline), np.percentile(hamm_zero_basline, 2.5), np.percentile(hamm_zero_basline, 97.5)))\n",
    "print(\"    Micro Avg F1 score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(f1_zero_basline), np.percentile(f1_zero_basline, 2.5), np.percentile(f1_zero_basline, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Label proportion baseline estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores for label proportion baseline with MultiOutputClassifier with 95% confidence intervals:\n",
      "    AUPRC macro: 0.17 [0.16, 0.18]\n",
      "    AUROC macro: 0.50 [0.50, 0.50]\n",
      "    Brier score: 0.11 [0.11, 0.12]\n",
      "    Hamming loss: 0.15 [0.14, 0.15]\n",
      "    Micro Avg F1 score: 0.40 [0.38, 0.42]\n"
     ]
    }
   ],
   "source": [
    "auprc_lprop_basline = []\n",
    "auroc_lprop_basline = []\n",
    "brier_lprop_basline = []\n",
    "f1_lprop_basline = []\n",
    "hamm_lprop_basline = []\n",
    "\n",
    "lprop_baseline_clf = DummyClassifier(strategy='prior', random_state=0)\n",
    "lprop_baseline_meta_clf = MultiOutputClassifier(lprop_baseline_clf)\n",
    "lprop_baseline_meta_clf = lprop_baseline_meta_clf.fit(X_train, Y_train)\n",
    "\n",
    "for i in range(100):\n",
    "    X_test_resampled, y_test_resampled = resample(X_test, Y_test, replace=True, n_samples=len(Y_test), random_state=0+i)\n",
    "\n",
    "    y_prob = lprop_baseline_meta_clf.predict_proba(X_test_resampled)\n",
    "    y_pred = lprop_baseline_meta_clf.predict(X_test_resampled)\n",
    "\n",
    "    # Combine prediction probas into single ndarray\n",
    "    y_prob_combined = y_prob[0][:,1].reshape(-1,1)\n",
    "    for i in range(len(y_prob)):\n",
    "        if i == (len(y_prob))-1:\n",
    "            break\n",
    "        else:\n",
    "            y_prob_combined = np.concatenate([y_prob_combined, y_prob[i+1][:,1].reshape(-1,1)], axis=1)\n",
    "\n",
    "    # Compute brier score\n",
    "    brier_scores = np.zeros(len(y_prob))\n",
    "    for i in range(len(y_prob)):\n",
    "        brier_scores[i] = brier_score_loss(y_test_resampled.iloc[:,i], y_prob[i][:,1])\n",
    "    brier_lprop_basline.append(brier_scores.mean()) \n",
    "    \n",
    "    # Other metrics\n",
    "    auprc_lprop_basline.append(average_precision_score(y_test_resampled, y_prob_combined, average='macro')) \n",
    "    auroc_lprop_basline.append(roc_auc_score(y_test_resampled, y_prob_combined, average='macro'))\n",
    "    f1_lprop_basline.append(f1_score(y_test_resampled, y_pred, average='micro'))\n",
    "    hamm_lprop_basline.append(hamming_loss(y_test_resampled, y_pred))\n",
    "\n",
    "print(f\"Mean scores for label proportion baseline with MultiOutputClassifier with 95% confidence intervals:\")\n",
    "print(\"    AUPRC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auprc_lprop_basline), np.percentile(auprc_lprop_basline, 2.5), np.percentile(auprc_lprop_basline, 97.5)))\n",
    "print(\"    AUROC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auroc_lprop_basline), np.percentile(auroc_lprop_basline, 2.5), np.percentile(auroc_lprop_basline, 97.5)))\n",
    "print(\"    Brier score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(brier_lprop_basline), np.percentile(brier_lprop_basline, 2.5), np.percentile(brier_lprop_basline, 97.5)))\n",
    "print(\"    Hamming loss: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(hamm_lprop_basline), np.percentile(hamm_lprop_basline, 2.5), np.percentile(hamm_lprop_basline, 97.5)))\n",
    "print(\"    Micro Avg F1 score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(f1_lprop_basline), np.percentile(f1_lprop_basline, 2.5), np.percentile(f1_lprop_basline, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores for LR with MultiOutputClassifier with 95% confidence intervals:\n",
      "    AUPRC macro: 0.20 [0.19, 0.22]\n",
      "    AUROC macro: 0.55 [0.53, 0.57]\n",
      "    Brier score: 0.23 [0.22, 0.24]\n",
      "    Hamming loss: 0.28 [0.27, 0.29]\n",
      "    Micro Avg F1 score: 0.34 [0.32, 0.36]\n"
     ]
    }
   ],
   "source": [
    "auprc_LR_meta = []\n",
    "auroc_LR_meta = []\n",
    "brier_LR_meta = []\n",
    "f1_LR_meta = []\n",
    "hamm_LR_meta = []\n",
    "\n",
    "LR_base_clf = LogisticRegression(class_weight='balanced', max_iter=10000, random_state=0)\n",
    "LR_meta_clf = MultiOutputClassifier(LR_base_clf, n_jobs=-1)\n",
    "LR_meta_clf = LR_meta_clf.fit(X_train, Y_train)\n",
    "\n",
    "for i in range(100):\n",
    "    X_test_resampled, y_test_resampled = resample(X_test, Y_test, replace=True, n_samples=len(Y_test), random_state=0+i)\n",
    "\n",
    "    Y_prob = LR_meta_clf.predict_proba(X_test_resampled)\n",
    "    Y_pred = LR_meta_clf.predict(X_test_resampled)\n",
    "\n",
    "    # Combine prediction probas into single ndarray\n",
    "    Y_prob_merged = Y_prob[0][:,1].reshape(-1,1)\n",
    "    for i in range(1, len(Y.columns), 1):\n",
    "            Y_prob_merged = np.concatenate([Y_prob_merged, Y_prob[i][:,1].reshape(-1,1)], axis=1)\n",
    "    \n",
    "    # Compute brier score\n",
    "    brier_scores = np.zeros(len(Y.columns))\n",
    "    for i in range(len(Y.columns)):\n",
    "        brier_scores[i] = brier_score_loss(y_test_resampled.iloc[:,i], Y_prob_merged[:, i])\n",
    "    brier_LR_meta.append(brier_scores.mean())\n",
    "\n",
    "    # Other metrics\n",
    "    auprc_LR_meta.append(average_precision_score(y_test_resampled, Y_prob_merged, average='macro')) \n",
    "    auroc_LR_meta.append(roc_auc_score(y_test_resampled, Y_prob_merged, average='macro'))\n",
    "    f1_LR_meta.append(f1_score(y_test_resampled, Y_pred, average='micro'))\n",
    "    hamm_LR_meta.append(hamming_loss(y_test_resampled, Y_pred))\n",
    "\n",
    "\n",
    "print(f\"Mean scores for LR with MultiOutputClassifier with 95% confidence intervals:\")\n",
    "print(\"    AUPRC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auprc_LR_meta), np.percentile(auprc_LR_meta, 2.5), np.percentile(auprc_LR_meta, 97.5)))\n",
    "print(\"    AUROC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auroc_LR_meta), np.percentile(auroc_LR_meta, 2.5), np.percentile(auroc_LR_meta, 97.5)))\n",
    "print(\"    Brier score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(brier_LR_meta), np.percentile(brier_LR_meta, 2.5), np.percentile(brier_LR_meta, 97.5)))\n",
    "print(\"    Hamming loss: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(hamm_LR_meta), np.percentile(hamm_LR_meta, 2.5), np.percentile(hamm_LR_meta, 97.5)))\n",
    "print(\"    Micro Avg F1 score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(f1_LR_meta), np.percentile(f1_LR_meta, 2.5), np.percentile(f1_LR_meta, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores for SVM with MultiOutputClassifier with 95% confidence intervals:\n",
      "    AUPRC macro: 0.20 [0.19, 0.22]\n",
      "    AUROC macro: 0.55 [0.53, 0.57]\n",
      "    Brier score: 0.23 [0.22, 0.24]\n",
      "    Hamming loss: 0.28 [0.27, 0.29]\n",
      "    Micro Avg F1 score: 0.34 [0.32, 0.36]\n"
     ]
    }
   ],
   "source": [
    "auprc_SVM_meta = []\n",
    "auroc_SVM_meta = []\n",
    "brier_SVM_meta = []\n",
    "f1_SVM_meta = []\n",
    "hamm_SVM_meta = []\n",
    "\n",
    "SVC_base_clf = SVC(class_weight='balanced', kernel='rbf', gamma='scale', probability=True, random_state=0)\n",
    "SVC_meta_clf = MultiOutputClassifier(SVC_base_clf, n_jobs=-1)\n",
    "SVC_meta_clf = LR_meta_clf.fit(X_train, Y_train)\n",
    "\n",
    "for i in range(100):\n",
    "    X_test_resampled, y_test_resampled = resample(X_test, Y_test, replace=True, n_samples=len(Y_test), random_state=0+i)\n",
    "\n",
    "    Y_prob = SVC_meta_clf.predict_proba(X_test_resampled)\n",
    "    Y_pred = SVC_meta_clf.predict(X_test_resampled)\n",
    "\n",
    "    # Combine prediction probas into single ndarray\n",
    "    Y_prob_merged = Y_prob[0][:,1].reshape(-1,1)\n",
    "    for i in range(1, len(Y.columns), 1):\n",
    "            Y_prob_merged = np.concatenate([Y_prob_merged, Y_prob[i][:,1].reshape(-1,1)], axis=1)\n",
    "    \n",
    "    # Compute brier score\n",
    "    brier_scores = np.zeros(len(Y.columns))\n",
    "    for i in range(len(Y.columns)):\n",
    "        brier_scores[i] = brier_score_loss(y_test_resampled.iloc[:,i], Y_prob_merged[:, i])\n",
    "    brier_SVM_meta.append(brier_scores.mean())\n",
    "\n",
    "    # Other metrics\n",
    "    auprc_SVM_meta.append(average_precision_score(y_test_resampled, Y_prob_merged, average='macro')) \n",
    "    auroc_SVM_meta.append(roc_auc_score(y_test_resampled, Y_prob_merged, average='macro'))\n",
    "    f1_SVM_meta.append(f1_score(y_test_resampled, Y_pred, average='micro'))\n",
    "    hamm_SVM_meta.append(hamming_loss(y_test_resampled, Y_pred))\n",
    "\n",
    "\n",
    "print(f\"Mean scores for SVM with MultiOutputClassifier with 95% confidence intervals:\")\n",
    "print(\"    AUPRC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auprc_SVM_meta), np.percentile(auprc_SVM_meta, 2.5), np.percentile(auprc_SVM_meta, 97.5)))\n",
    "print(\"    AUROC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auroc_SVM_meta), np.percentile(auroc_SVM_meta, 2.5), np.percentile(auroc_SVM_meta, 97.5)))\n",
    "print(\"    Brier score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(brier_SVM_meta), np.percentile(brier_SVM_meta, 2.5), np.percentile(brier_SVM_meta, 97.5)))\n",
    "print(\"    Hamming loss: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(hamm_SVM_meta), np.percentile(hamm_SVM_meta, 2.5), np.percentile(hamm_SVM_meta, 97.5)))\n",
    "print(\"    Micro Avg F1 score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(f1_SVM_meta), np.percentile(f1_SVM_meta, 2.5), np.percentile(f1_SVM_meta, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores for RF with MultiOutputClassifier with 95% confidence intervals:\n",
      "    AUPRC macro: 0.20 [0.19, 0.22]\n",
      "    AUROC macro: 0.55 [0.53, 0.57]\n",
      "    Brier score: 0.23 [0.22, 0.24]\n",
      "    Hamming loss: 0.28 [0.27, 0.29]\n",
      "    Micro Avg F1 score: 0.34 [0.32, 0.36]\n"
     ]
    }
   ],
   "source": [
    "auprc_RF_meta = []\n",
    "auroc_RF_meta = []\n",
    "brier_RF_meta = []\n",
    "f1_RF_meta = []\n",
    "hamm_RF_meta = []\n",
    "\n",
    "RF_base_clf = RandomForestClassifier(random_state=0)\n",
    "RF_meta_clf = MultiOutputClassifier(RF_base_clf, n_jobs=-1)\n",
    "RF_meta_clf = LR_meta_clf.fit(X_train, Y_train)\n",
    "\n",
    "for i in range(100):\n",
    "    X_test_resampled, y_test_resampled = resample(X_test, Y_test, replace=True, n_samples=len(Y_test), random_state=0+i)\n",
    "\n",
    "    Y_prob = RF_meta_clf.predict_proba(X_test_resampled)\n",
    "    Y_pred = RF_meta_clf.predict(X_test_resampled)\n",
    "\n",
    "    # Combine prediction probas into single ndarray\n",
    "    Y_prob_merged = Y_prob[0][:,1].reshape(-1,1)\n",
    "    for i in range(1, len(Y.columns), 1):\n",
    "            Y_prob_merged = np.concatenate([Y_prob_merged, Y_prob[i][:,1].reshape(-1,1)], axis=1)\n",
    "    \n",
    "    # Compute brier score\n",
    "    brier_scores = np.zeros(len(Y.columns))\n",
    "    for i in range(len(Y.columns)):\n",
    "        brier_scores[i] = brier_score_loss(y_test_resampled.iloc[:,i], Y_prob_merged[:, i])\n",
    "    brier_RF_meta.append(brier_scores.mean())\n",
    "\n",
    "    # Other metrics\n",
    "    auprc_RF_meta.append(average_precision_score(y_test_resampled, Y_prob_merged, average='macro')) \n",
    "    auroc_RF_meta.append(roc_auc_score(y_test_resampled, Y_prob_merged, average='macro'))\n",
    "    f1_RF_meta.append(f1_score(y_test_resampled, Y_pred, average='micro'))\n",
    "    hamm_RF_meta.append(hamming_loss(y_test_resampled, Y_pred))\n",
    "\n",
    "\n",
    "print(f\"Mean scores for RF with MultiOutputClassifier with 95% confidence intervals:\")\n",
    "print(\"    AUPRC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auprc_RF_meta), np.percentile(auprc_RF_meta, 2.5), np.percentile(auprc_RF_meta, 97.5)))\n",
    "print(\"    AUROC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auroc_RF_meta), np.percentile(auroc_RF_meta, 2.5), np.percentile(auroc_RF_meta, 97.5)))\n",
    "print(\"    Brier score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(brier_RF_meta), np.percentile(brier_RF_meta, 2.5), np.percentile(brier_RF_meta, 97.5)))\n",
    "print(\"    Hamming loss: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(hamm_RF_meta), np.percentile(hamm_RF_meta, 2.5), np.percentile(hamm_RF_meta, 97.5)))\n",
    "print(\"    Micro Avg F1 score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(f1_RF_meta), np.percentile(f1_RF_meta, 2.5), np.percentile(f1_RF_meta, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Histogram-based Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores for HGB with MultiOutputClassifier with 95% confidence intervals:\n",
      "    AUPRC macro: 0.22 [0.21, 0.24]\n",
      "    AUROC macro: 0.59 [0.57, 0.62]\n",
      "    Brier score: 0.12 [0.12, 0.13]\n",
      "    Hamming loss: 0.15 [0.14, 0.16]\n",
      "    Micro Avg F1 score: 0.39 [0.37, 0.41]\n"
     ]
    }
   ],
   "source": [
    "auprc_HGB_meta = []\n",
    "auroc_HGB_meta = []\n",
    "brier_HGB_meta = []\n",
    "f1_HGB_meta = []\n",
    "hamm_HGB_meta = []\n",
    "\n",
    "HGB_base_clf = HistGradientBoostingClassifier(random_state=0)\n",
    "HGB_meta_clf = MultiOutputClassifier(HGB_base_clf, n_jobs=-1)\n",
    "HGB_meta_clf = HGB_meta_clf.fit(X_train, Y_train)\n",
    "\n",
    "for i in range(100):\n",
    "    X_test_resampled, y_test_resampled = resample(X_test, Y_test, replace=True, n_samples=len(Y_test), random_state=0+i)\n",
    "\n",
    "    Y_prob = HGB_meta_clf.predict_proba(X_test_resampled)\n",
    "    Y_pred = HGB_meta_clf.predict(X_test_resampled)\n",
    "\n",
    "    # Combine prediction probas into single ndarray\n",
    "    Y_prob_merged = Y_prob[0][:,1].reshape(-1,1)\n",
    "    for i in range(1, len(Y.columns), 1):\n",
    "            Y_prob_merged = np.concatenate([Y_prob_merged, Y_prob[i][:,1].reshape(-1,1)], axis=1)\n",
    "    \n",
    "    # Compute brier score\n",
    "    brier_scores = np.zeros(len(Y.columns))\n",
    "    for i in range(len(Y.columns)):\n",
    "        brier_scores[i] = brier_score_loss(y_test_resampled.iloc[:,i], Y_prob_merged[:, i])\n",
    "    brier_HGB_meta.append(brier_scores.mean())\n",
    "\n",
    "    # Other metrics\n",
    "    auprc_HGB_meta.append(average_precision_score(y_test_resampled, Y_prob_merged, average='macro')) \n",
    "    auroc_HGB_meta.append(roc_auc_score(y_test_resampled, Y_prob_merged, average='macro'))\n",
    "    f1_HGB_meta.append(f1_score(y_test_resampled, Y_pred, average='micro'))\n",
    "    hamm_HGB_meta.append(hamming_loss(y_test_resampled, Y_pred))\n",
    "\n",
    "print(f\"Mean scores for HGB with MultiOutputClassifier with 95% confidence intervals:\")\n",
    "print(\"    AUPRC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auprc_HGB_meta), np.percentile(auprc_HGB_meta, 2.5), np.percentile(auprc_HGB_meta, 97.5)))\n",
    "print(\"    AUROC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auroc_HGB_meta), np.percentile(auroc_HGB_meta, 2.5), np.percentile(auroc_HGB_meta, 97.5)))\n",
    "print(\"    Brier score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(brier_HGB_meta), np.percentile(brier_HGB_meta, 2.5), np.percentile(brier_HGB_meta, 97.5)))\n",
    "print(\"    Hamming loss: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(hamm_HGB_meta), np.percentile(hamm_HGB_meta, 2.5), np.percentile(hamm_HGB_meta, 97.5)))\n",
    "print(\"    Micro Avg F1 score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(f1_HGB_meta), np.percentile(f1_HGB_meta, 2.5), np.percentile(f1_HGB_meta, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7. MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores for MLP with MultiOutputClassifier with 95% confidence intervals:\n",
      "    AUPRC macro: 0.21 [0.20, 0.23]\n",
      "    AUROC macro: 0.58 [0.56, 0.60]\n",
      "    Brier score: 0.16 [0.15, 0.16]\n",
      "    Hamming loss: 0.18 [0.18, 0.19]\n",
      "    Micro Avg F1 score: 0.38 [0.36, 0.40]\n"
     ]
    }
   ],
   "source": [
    "auprc_MLP_meta = []\n",
    "auroc_MLP_meta = []\n",
    "brier_MLP_meta = []\n",
    "f1_MLP_meta = []\n",
    "hamm_MLP_meta = []\n",
    "\n",
    "MLP_base_clf = MLPClassifier(random_state=0)\n",
    "MLP_meta_clf = MultiOutputClassifier(MLP_base_clf, n_jobs=-1)\n",
    "MLP_meta_clf = MLP_meta_clf.fit(X_train, Y_train)\n",
    "\n",
    "for i in range(100):\n",
    "    X_test_resampled, y_test_resampled = resample(X_test, Y_test, replace=True, n_samples=len(Y_test), random_state=0+i)\n",
    "\n",
    "    Y_prob = MLP_meta_clf.predict_proba(X_test_resampled)\n",
    "    Y_pred = MLP_meta_clf.predict(X_test_resampled)\n",
    "\n",
    "    # Combine prediction probas into single ndarray\n",
    "    Y_prob_merged = Y_prob[0][:,1].reshape(-1,1)\n",
    "    for i in range(1, len(Y.columns), 1):\n",
    "            Y_prob_merged = np.concatenate([Y_prob_merged, Y_prob[i][:,1].reshape(-1,1)], axis=1)\n",
    "    \n",
    "    # Compute brier score\n",
    "    brier_scores = np.zeros(len(Y.columns))\n",
    "    for i in range(len(Y.columns)):\n",
    "        brier_scores[i] = brier_score_loss(y_test_resampled.iloc[:,i], Y_prob_merged[:, i])\n",
    "    brier_MLP_meta.append(brier_scores.mean())\n",
    "\n",
    "    # Other metrics\n",
    "    auprc_MLP_meta.append(average_precision_score(y_test_resampled, Y_prob_merged, average='macro')) \n",
    "    auroc_MLP_meta.append(roc_auc_score(y_test_resampled, Y_prob_merged, average='macro'))\n",
    "    f1_MLP_meta.append(f1_score(y_test_resampled, Y_pred, average='micro'))\n",
    "    hamm_MLP_meta.append(hamming_loss(y_test_resampled, Y_pred))\n",
    "\n",
    "print(f\"Mean scores for MLP with MultiOutputClassifier with 95% confidence intervals:\")\n",
    "print(\"    AUPRC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auprc_MLP_meta), np.percentile(auprc_MLP_meta, 2.5), np.percentile(auprc_MLP_meta, 97.5)))\n",
    "print(\"    AUROC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auroc_MLP_meta), np.percentile(auroc_MLP_meta, 2.5), np.percentile(auroc_MLP_meta, 97.5)))\n",
    "print(\"    Brier score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(brier_MLP_meta), np.percentile(brier_MLP_meta, 2.5), np.percentile(brier_MLP_meta, 97.5)))\n",
    "print(\"    Hamming loss: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(hamm_MLP_meta), np.percentile(hamm_MLP_meta, 2.5), np.percentile(hamm_MLP_meta, 97.5)))\n",
    "print(\"    Micro Avg F1 score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(f1_MLP_meta), np.percentile(f1_MLP_meta, 2.5), np.percentile(f1_MLP_meta, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ClassifierChain (ordered by frequency) \n",
    "Evaluate classification models wrapped in meta estimator ClassifierChain with respect to multi-label performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_freq = label_freq_sorted(Y_train) # list for ordered ClassifierChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Always zero baseline estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores for always zero baseline with ClassifierChain (ordered by frequency) with 95% confidence intervals:\n",
      "    AUPRC macro: 0.17 [0.16, 0.18]\n",
      "    AUROC macro: 0.50 [0.50, 0.50]\n",
      "    Brier score: 0.17 [0.16, 0.18]\n",
      "    Hamming loss: 0.17 [0.16, 0.18]\n",
      "    Micro Avg F1 score: 0.00 [0.00, 0.00]\n"
     ]
    }
   ],
   "source": [
    "auprc_zero_basline_chain = []\n",
    "auroc_zero_basline_chain = []\n",
    "brier_zero_basline_chain = []\n",
    "hamm_zero_basline_chain = []\n",
    "f1_zero_basline_chain = []\n",
    "\n",
    "zero_baseline_clf = DummyClassifier(strategy='constant', constant=0 ,random_state=0)\n",
    "zero_baseline_meta_chain_clf = ClassifierChain(zero_baseline_clf, order=by_freq, random_state=0)\n",
    "zero_baseline_meta_chain_clf = zero_baseline_meta_chain_clf.fit(X_train, Y_train)\n",
    "\n",
    "for i in range(100):\n",
    "    X_test_resampled, y_test_resampled = resample(X_test, Y_test, replace=True, n_samples=len(Y_test), random_state=0+i)\n",
    "\n",
    "    y_prob = zero_baseline_meta_chain_clf.predict_proba(X_test_resampled)\n",
    "    y_pred = zero_baseline_meta_chain_clf.predict(X_test_resampled)\n",
    "\n",
    "    # Compute brier score\n",
    "    brier_scores = np.zeros(y_prob.shape[1])\n",
    "    for i in range(y_prob.shape[1]):\n",
    "        brier_scores[i] = brier_score_loss(y_test_resampled.iloc[:,i], y_prob[:,i])\n",
    "    brier_zero_basline_chain.append(brier_scores.mean()) \n",
    "    \n",
    "    # Other metrics\n",
    "    auprc_zero_basline_chain.append(average_precision_score(y_test_resampled, y_prob, average='macro')) \n",
    "    auroc_zero_basline_chain.append(roc_auc_score(y_test_resampled, y_prob, average='macro'))\n",
    "    f1_zero_basline_chain.append(f1_score(y_test_resampled, y_pred, average='micro'))\n",
    "    hamm_zero_basline_chain.append(hamming_loss(y_test_resampled, y_pred))\n",
    "\n",
    "print(f\"Mean scores for always zero baseline with ClassifierChain (ordered by frequency) with 95% confidence intervals:\")\n",
    "print(\"    AUPRC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auprc_zero_basline_chain), np.percentile(auprc_zero_basline_chain, 2.5), np.percentile(auprc_zero_basline_chain, 97.5)))\n",
    "print(\"    AUROC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auroc_zero_basline_chain), np.percentile(auroc_zero_basline_chain, 2.5), np.percentile(auroc_zero_basline_chain, 97.5)))\n",
    "print(\"    Brier score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(brier_zero_basline_chain), np.percentile(brier_zero_basline_chain, 2.5), np.percentile(brier_zero_basline_chain, 97.5)))\n",
    "print(\"    Hamming loss: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(hamm_zero_basline_chain), np.percentile(hamm_zero_basline_chain, 2.5), np.percentile(hamm_zero_basline_chain, 97.5)))\n",
    "print(\"    Micro Avg F1 score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(f1_zero_basline_chain), np.percentile(f1_zero_basline_chain, 2.5), np.percentile(f1_zero_basline_chain, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Label proportion baseline estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores for label proportion baseline with ClassifierChain (ordered by frequency) with 95% confidence intervals:\n",
      "    AUPRC macro: 0.17 [0.16, 0.18]\n",
      "    AUROC macro: 0.50 [0.50, 0.50]\n",
      "    Brier score: 0.17 [0.16, 0.18]\n",
      "    Hamming loss: 0.17 [0.16, 0.18]\n",
      "    Micro Avg F1 score: 0.00 [0.00, 0.00]\n"
     ]
    }
   ],
   "source": [
    "auprc_lprop_basline_chain_r = []\n",
    "auroc_lprop_basline_chain_r = []\n",
    "brier_lprop_basline_chain_r = []\n",
    "f1_lprop_basline_chain_r = []\n",
    "hamm_lprop_basline_chain_r = []\n",
    "\n",
    "lprop_baseline_clf = DummyClassifier(strategy='prior', random_state=0)\n",
    "lprop_baseline_meta_chain_r_clf = ClassifierChain(zero_baseline_clf, order=by_freq, random_state=0)\n",
    "lprop_baseline_meta_chain_r_clf = lprop_baseline_meta_chain_r_clf.fit(X_train, Y_train)\n",
    "\n",
    "for i in range(100):\n",
    "    X_test_resampled, y_test_resampled = resample(X_test, Y_test, replace=True, n_samples=len(Y_test), random_state=0+i)\n",
    "    \n",
    "\n",
    "    y_prob = lprop_baseline_meta_chain_r_clf.predict_proba(X_test_resampled)\n",
    "    y_pred = lprop_baseline_meta_chain_r_clf.predict(X_test_resampled)\n",
    "\n",
    "    # Compute brier score\n",
    "    brier_scores = np.zeros(y_prob.shape[1])\n",
    "    for i in range(y_prob.shape[1]):\n",
    "        brier_scores[i] = brier_score_loss(y_test_resampled.iloc[:,i], y_prob[:,i])\n",
    "    brier_lprop_basline_chain_r.append(brier_scores.mean()) \n",
    "    \n",
    "    # Other metrics\n",
    "    auprc_lprop_basline_chain_r.append(average_precision_score(y_test_resampled, y_prob, average='macro')) \n",
    "    auroc_lprop_basline_chain_r.append(roc_auc_score(y_test_resampled, y_prob, average='macro'))\n",
    "    f1_lprop_basline_chain_r.append(f1_score(y_test_resampled, y_pred, average='micro'))\n",
    "    hamm_lprop_basline_chain_r.append(hamming_loss(y_test_resampled, y_pred))\n",
    "\n",
    "print(f\"Mean scores for label proportion baseline with ClassifierChain (ordered by frequency) with 95% confidence intervals:\")\n",
    "print(\"    AUPRC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auprc_lprop_basline_chain_r), np.percentile(auprc_lprop_basline_chain_r, 2.5), np.percentile(auprc_lprop_basline_chain_r, 97.5)))\n",
    "print(\"    AUROC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auroc_lprop_basline_chain_r), np.percentile(auroc_lprop_basline_chain_r, 2.5), np.percentile(auroc_lprop_basline_chain_r, 97.5)))\n",
    "print(\"    Brier score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(brier_lprop_basline_chain_r), np.percentile(brier_lprop_basline_chain_r, 2.5), np.percentile(brier_lprop_basline_chain_r, 97.5)))\n",
    "print(\"    Hamming loss: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(hamm_lprop_basline_chain_r), np.percentile(hamm_lprop_basline_chain_r, 2.5), np.percentile(hamm_lprop_basline_chain_r, 97.5)))\n",
    "print(\"    Micro Avg F1 score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(f1_lprop_basline_chain_r), np.percentile(f1_lprop_basline_chain_r, 2.5), np.percentile(f1_lprop_basline_chain_r, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores for LR with ClassifierChain (ordered by frequency) with 95% confidence intervals:\n",
      "    AUPRC macro: 0.20 [0.19, 0.22]\n",
      "    AUROC macro: 0.55 [0.53, 0.58]\n",
      "    Brier score: 0.23 [0.22, 0.23]\n",
      "    Hamming loss: 0.28 [0.27, 0.28]\n",
      "    Micro Avg F1 score: 0.35 [0.33, 0.37]\n"
     ]
    }
   ],
   "source": [
    "auprc_LR_meta_chain = []\n",
    "auroc_LR_meta_chain = []\n",
    "brier_LR_meta_chain = []\n",
    "f1_LR_meta_chain = []\n",
    "hamm_LR_meta_chain = []\n",
    "\n",
    "LR_base_clf = LogisticRegression(class_weight='balanced', max_iter=10000, random_state=0, n_jobs=-1)\n",
    "LR_meta_chain_clf = ClassifierChain(LR_base_clf, order=by_freq, random_state=0)\n",
    "LR_meta_chain_clf = LR_meta_chain_clf.fit(X_train, Y_train)\n",
    "\n",
    "for i in range(100):\n",
    "    X_test_resampled, y_test_resampled = resample(X_test, Y_test, replace=True, n_samples=len(Y_test), random_state=0+i)\n",
    "\n",
    "    Y_prob = LR_meta_chain_clf.predict_proba(X_test_resampled)\n",
    "    Y_pred = LR_meta_chain_clf.predict(X_test_resampled)\n",
    "    \n",
    "    # Compute brier score\n",
    "    brier_scores = np.zeros(Y_prob.shape[1])\n",
    "    for i in range(Y_prob.shape[1]):\n",
    "        brier_scores[i] = brier_score_loss(y_test_resampled.iloc[:,i], Y_prob[:, i])\n",
    "    brier_LR_meta_chain.append(brier_scores.mean())\n",
    "\n",
    "    # Other metrics\n",
    "    auprc_LR_meta_chain.append(average_precision_score(y_test_resampled, Y_prob, average='macro')) \n",
    "    auroc_LR_meta_chain.append(roc_auc_score(y_test_resampled, Y_prob, average='macro'))\n",
    "    f1_LR_meta_chain.append(f1_score(y_test_resampled, Y_pred, average='micro'))\n",
    "    hamm_LR_meta_chain.append(hamming_loss(y_test_resampled, Y_pred))\n",
    "\n",
    "\n",
    "print(f\"Mean scores for LR with ClassifierChain (ordered by frequency) with 95% confidence intervals:\")\n",
    "print(\"    AUPRC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auprc_LR_meta_chain), np.percentile(auprc_LR_meta_chain, 2.5), np.percentile(auprc_LR_meta_chain, 97.5)))\n",
    "print(\"    AUROC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auroc_LR_meta_chain), np.percentile(auroc_LR_meta_chain, 2.5), np.percentile(auroc_LR_meta_chain, 97.5)))\n",
    "print(\"    Brier score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(brier_LR_meta_chain), np.percentile(brier_LR_meta_chain, 2.5), np.percentile(brier_LR_meta_chain, 97.5)))\n",
    "print(\"    Hamming loss: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(hamm_LR_meta_chain), np.percentile(hamm_LR_meta_chain, 2.5), np.percentile(hamm_LR_meta_chain, 97.5)))\n",
    "print(\"    Micro Avg F1 score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(f1_LR_meta_chain), np.percentile(f1_LR_meta_chain, 2.5), np.percentile(f1_LR_meta_chain, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores for SVM with ClassifierChain (ordered by frequency) with 95% confidence intervals:\n",
      "    AUPRC macro: 0.20 [0.20, 0.21]\n",
      "    AUROC macro: 0.55 [0.53, 0.57]\n",
      "    Brier score: 0.23 [0.22, 0.23]\n",
      "    Hamming loss: 0.28 [0.27, 0.28]\n",
      "    Micro Avg F1 score: 0.35 [0.34, 0.36]\n"
     ]
    }
   ],
   "source": [
    "auprc_SVM_meta_chain = []\n",
    "auroc_SVM_meta_chain = []\n",
    "brier_SVM_meta_chain = []\n",
    "f1_SVM_meta_chain = []\n",
    "hamm_SVM_meta_chain = []\n",
    "\n",
    "SVC_base_clf = SVC(class_weight='balanced', kernel='rbf', gamma='scale', probability=True, random_state=0)\n",
    "SVC_meta_chain_clf = ClassifierChain(SVC_base_clf, order=by_freq, random_state=0)\n",
    "SVC_meta_chain_clf = LR_meta_chain_clf.fit(X_train, Y_train)\n",
    "\n",
    "for i in range(10):\n",
    "    X_test_resampled, y_test_resampled = resample(X_test, Y_test, replace=True, n_samples=len(Y_test), random_state=0+i)\n",
    "\n",
    "    Y_prob = SVC_meta_chain_clf.predict_proba(X_test_resampled)\n",
    "    Y_pred = SVC_meta_chain_clf.predict(X_test_resampled)\n",
    "    \n",
    "    # Compute brier score\n",
    "    brier_scores = np.zeros(Y_prob.shape[1])\n",
    "    for i in range(Y_prob.shape[1]):\n",
    "        brier_scores[i] = brier_score_loss(y_test_resampled.iloc[:,i], Y_prob[:, i])\n",
    "    brier_SVM_meta_chain.append(brier_scores.mean())\n",
    "\n",
    "    # Other metrics\n",
    "    auprc_SVM_meta_chain.append(average_precision_score(y_test_resampled, Y_prob, average='macro')) \n",
    "    auroc_SVM_meta_chain.append(roc_auc_score(y_test_resampled, Y_prob, average='macro'))\n",
    "    f1_SVM_meta_chain.append(f1_score(y_test_resampled, Y_pred, average='micro'))\n",
    "    hamm_SVM_meta_chain.append(hamming_loss(y_test_resampled, Y_pred))\n",
    "\n",
    "\n",
    "print(f\"Mean scores for SVM with ClassifierChain (ordered by frequency) with 95% confidence intervals:\")\n",
    "print(\"    AUPRC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auprc_SVM_meta_chain), np.percentile(auprc_SVM_meta_chain, 2.5), np.percentile(auprc_SVM_meta_chain, 97.5)))\n",
    "print(\"    AUROC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auroc_SVM_meta_chain), np.percentile(auroc_SVM_meta_chain, 2.5), np.percentile(auroc_SVM_meta_chain, 97.5)))\n",
    "print(\"    Brier score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(brier_SVM_meta_chain), np.percentile(brier_SVM_meta_chain, 2.5), np.percentile(brier_SVM_meta_chain, 97.5)))\n",
    "print(\"    Hamming loss: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(hamm_SVM_meta_chain), np.percentile(hamm_SVM_meta_chain, 2.5), np.percentile(hamm_SVM_meta_chain, 97.5)))\n",
    "print(\"    Micro Avg F1 score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(f1_SVM_meta_chain), np.percentile(f1_SVM_meta_chain, 2.5), np.percentile(f1_SVM_meta_chain, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores for RF meta with ClassifierChain (ordered by frequency) with 95% confidence intervals:\n",
      "    AUPRC macro: 0.20 [0.19, 0.22]\n",
      "    AUROC macro: 0.55 [0.53, 0.58]\n",
      "    Brier score: 0.23 [0.22, 0.23]\n",
      "    Hamming loss: 0.28 [0.27, 0.28]\n",
      "    Micro Avg F1 score: 0.35 [0.33, 0.37]\n"
     ]
    }
   ],
   "source": [
    "auprc_RF_meta_chain = []\n",
    "auroc_RF_meta_chain = []\n",
    "brier_RF_meta_chain = []\n",
    "f1_RF_meta_chain = []\n",
    "hamm_RF_meta_chain = []\n",
    "\n",
    "RF_base_clf = RandomForestClassifier(n_jobs=-1, random_state=0)\n",
    "RF_meta_chain_clf = ClassifierChain(RF_base_clf, order=by_freq, random_state=0)\n",
    "RF_meta_chain_clf = LR_meta_chain_clf.fit(X_train, Y_train)\n",
    "\n",
    "for i in range(100):\n",
    "    X_test_resampled, y_test_resampled = resample(X_test, Y_test, replace=True, n_samples=len(Y_test), random_state=0+i)\n",
    "\n",
    "    Y_prob = RF_meta_chain_clf.predict_proba(X_test_resampled)\n",
    "    Y_pred = RF_meta_chain_clf.predict(X_test_resampled)\n",
    "    \n",
    "    # Compute brier score\n",
    "    brier_scores = np.zeros(Y_prob.shape[1])\n",
    "    for i in range(Y_prob.shape[1]):\n",
    "        brier_scores[i] = brier_score_loss(y_test_resampled.iloc[:,i], Y_prob[:, i])\n",
    "    brier_RF_meta_chain.append(brier_scores.mean())\n",
    "\n",
    "    # Other metrics\n",
    "    auprc_RF_meta_chain.append(average_precision_score(y_test_resampled, Y_prob, average='macro')) \n",
    "    auroc_RF_meta_chain.append(roc_auc_score(y_test_resampled, Y_prob, average='macro'))\n",
    "    f1_RF_meta_chain.append(f1_score(y_test_resampled, Y_pred, average='micro'))\n",
    "    hamm_RF_meta_chain.append(hamming_loss(y_test_resampled, Y_pred))\n",
    "\n",
    "\n",
    "print(f\"Mean scores for RF meta with ClassifierChain (ordered by frequency) with 95% confidence intervals:\")\n",
    "print(\"    AUPRC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auprc_RF_meta_chain), np.percentile(auprc_RF_meta_chain, 2.5), np.percentile(auprc_RF_meta_chain, 97.5)))\n",
    "print(\"    AUROC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auroc_RF_meta_chain), np.percentile(auroc_RF_meta_chain, 2.5), np.percentile(auroc_RF_meta_chain, 97.5)))\n",
    "print(\"    Brier score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(brier_RF_meta_chain), np.percentile(brier_RF_meta_chain, 2.5), np.percentile(brier_RF_meta_chain, 97.5)))\n",
    "print(\"    Hamming loss: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(hamm_RF_meta_chain), np.percentile(hamm_RF_meta_chain, 2.5), np.percentile(hamm_RF_meta_chain, 97.5)))\n",
    "print(\"    Micro Avg F1 score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(f1_RF_meta_chain), np.percentile(f1_RF_meta_chain, 2.5), np.percentile(f1_RF_meta_chain, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Histogram-based Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores for HGB with ClassifierChain (ordered by frequency) with 95% confidence intervals:\n",
      "    AUPRC macro: 0.22 [0.20, 0.23]\n",
      "    AUROC macro: 0.58 [0.55, 0.60]\n",
      "    Brier score: 0.12 [0.12, 0.13]\n",
      "    Hamming loss: 0.15 [0.14, 0.15]\n",
      "    Micro Avg F1 score: 0.39 [0.38, 0.40]\n"
     ]
    }
   ],
   "source": [
    "auprc_HGB_meta_chain = []\n",
    "auroc_HGB_meta_chain = []\n",
    "brier_HGB_meta_chain = []\n",
    "f1_HGB_meta_chain = []\n",
    "hamm_HGB_meta_chain = []\n",
    "\n",
    "\n",
    "HGB_base_clf = HistGradientBoostingClassifier(random_state=0)\n",
    "HGB_meta_chain_clf = ClassifierChain(HGB_base_clf, order=by_freq, random_state=0)\n",
    "HGB_meta_chain_clf = HGB_meta_chain_clf.fit(X_train, Y_train)\n",
    "\n",
    "for i in range(10):\n",
    "    X_test_resampled, y_test_resampled = resample(X_test, Y_test, replace=True, n_samples=len(Y_test), random_state=0+i)\n",
    "\n",
    "    Y_prob = HGB_meta_chain_clf.predict_proba(X_test_resampled)\n",
    "    Y_pred = HGB_meta_chain_clf.predict(X_test_resampled)\n",
    "    \n",
    "    # Compute brier score\n",
    "    brier_scores = np.zeros(Y_prob.shape[1])\n",
    "    for i in range(Y_prob.shape[1]):\n",
    "        brier_scores[i] = brier_score_loss(y_test_resampled.iloc[:,i], Y_prob[:, i])\n",
    "    brier_HGB_meta_chain.append(brier_scores.mean())\n",
    "\n",
    "    # Other metrics\n",
    "    auprc_HGB_meta_chain.append(average_precision_score(y_test_resampled, Y_prob, average='macro')) \n",
    "    auroc_HGB_meta_chain.append(roc_auc_score(y_test_resampled, Y_prob, average='macro'))\n",
    "    f1_HGB_meta_chain.append(f1_score(y_test_resampled, Y_pred, average='micro'))\n",
    "    hamm_HGB_meta_chain.append(hamming_loss(y_test_resampled, Y_pred))\n",
    "\n",
    "print(f\"Mean scores for HGB with ClassifierChain (ordered by frequency) with 95% confidence intervals:\")\n",
    "print(\"    AUPRC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auprc_HGB_meta_chain), np.percentile(auprc_HGB_meta_chain, 2.5), np.percentile(auprc_HGB_meta_chain, 97.5)))\n",
    "print(\"    AUROC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auroc_HGB_meta_chain), np.percentile(auroc_HGB_meta_chain, 2.5), np.percentile(auroc_HGB_meta_chain, 97.5)))\n",
    "print(\"    Brier score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(brier_HGB_meta_chain), np.percentile(brier_HGB_meta_chain, 2.5), np.percentile(brier_HGB_meta_chain, 97.5)))\n",
    "print(\"    Hamming loss: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(hamm_HGB_meta_chain), np.percentile(hamm_HGB_meta_chain, 2.5), np.percentile(hamm_HGB_meta_chain, 97.5)))\n",
    "print(\"    Micro Avg F1 score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(f1_HGB_meta_chain), np.percentile(f1_HGB_meta_chain, 2.5), np.percentile(f1_HGB_meta_chain, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7. MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores for MLP with ClassifierChain (ordered by frequency) with 95% confidence intervals:\n",
      "    AUPRC macro: 0.21 [0.20, 0.23]\n",
      "    AUROC macro: 0.57 [0.55, 0.60]\n",
      "    Brier score: 0.16 [0.15, 0.16]\n",
      "    Hamming loss: 0.18 [0.18, 0.19]\n",
      "    Micro Avg F1 score: 0.37 [0.35, 0.39]\n"
     ]
    }
   ],
   "source": [
    "auprc_MLP_meta_chain = []\n",
    "auroc_MLP_meta_chain = []\n",
    "brier_MLP_meta_chain = []\n",
    "f1_MLP_meta_chain = []\n",
    "hamm_MLP_meta_chain = []\n",
    "\n",
    "MLP_base_clf = MLPClassifier(random_state=0)\n",
    "MLP_meta_chain_clf = ClassifierChain(MLP_base_clf, order=by_freq, random_state=0)\n",
    "MLP_meta_chain_clf = MLP_meta_chain_clf.fit(X_train, Y_train)\n",
    "\n",
    "for i in range(100):\n",
    "    X_test_resampled, y_test_resampled = resample(X_test, Y_test, replace=True, n_samples=len(Y_test), random_state=0+i)\n",
    "\n",
    "    Y_prob = MLP_meta_chain_clf.predict_proba(X_test_resampled)\n",
    "    Y_pred = MLP_meta_chain_clf.predict(X_test_resampled)\n",
    "\n",
    "    # Compute brier score\n",
    "    brier_scores = np.zeros(Y_prob.shape[1])\n",
    "    for i in range(Y_prob.shape[1]):\n",
    "        brier_scores[i] = brier_score_loss(y_test_resampled.iloc[:,i], Y_prob[:, i])\n",
    "    brier_MLP_meta_chain.append(brier_scores.mean())\n",
    "\n",
    "    # Other metrics\n",
    "    auprc_MLP_meta_chain.append(average_precision_score(y_test_resampled, Y_prob, average='macro')) \n",
    "    auroc_MLP_meta_chain.append(roc_auc_score(y_test_resampled, Y_prob, average='macro'))\n",
    "    f1_MLP_meta_chain.append(f1_score(y_test_resampled, Y_pred, average='micro'))\n",
    "    hamm_MLP_meta_chain.append(hamming_loss(y_test_resampled, Y_pred))\n",
    "\n",
    "print(f\"Mean scores for MLP with ClassifierChain (ordered by frequency) with 95% confidence intervals:\")\n",
    "print(\"    AUPRC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auprc_MLP_meta_chain), np.percentile(auprc_MLP_meta_chain, 2.5), np.percentile(auprc_MLP_meta_chain, 97.5)))\n",
    "print(\"    AUROC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auroc_MLP_meta_chain), np.percentile(auroc_MLP_meta_chain, 2.5), np.percentile(auroc_MLP_meta_chain, 97.5)))\n",
    "print(\"    Brier score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(brier_MLP_meta_chain), np.percentile(brier_MLP_meta_chain, 2.5), np.percentile(brier_MLP_meta_chain, 97.5)))\n",
    "print(\"    Hamming loss: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(hamm_MLP_meta_chain), np.percentile(hamm_MLP_meta_chain, 2.5), np.percentile(hamm_MLP_meta_chain, 97.5)))\n",
    "print(\"    Micro Avg F1 score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(f1_MLP_meta_chain), np.percentile(f1_MLP_meta_chain, 2.5), np.percentile(f1_MLP_meta_chain, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ClassifierChain (random order) \n",
    "Evaluate classification models wrapped in meta estimator ClassifierChain with respect to multi-label performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Always zero baseline estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores for always zero baseline with ClassifierChain (random order) with 95% confidence intervals:\n",
      "    AUPRC macro: 0.17 [0.16, 0.18]\n",
      "    AUROC macro: 0.50 [0.50, 0.50]\n",
      "    Brier score: 0.17 [0.16, 0.18]\n",
      "    Hamming loss: 0.17 [0.16, 0.18]\n",
      "    Micro Avg F1 score: 0.00 [0.00, 0.00]\n"
     ]
    }
   ],
   "source": [
    "auprc_zero_basline_chain_r = []\n",
    "auroc_zero_basline_chain_r = []\n",
    "brier_zero_basline_chain_r = []\n",
    "hamm_zero_basline_chain_r = []\n",
    "f1_zero_basline_chain_r = []\n",
    "\n",
    "zero_baseline_clf = DummyClassifier(strategy='constant', constant=0 ,random_state=0)\n",
    "zero_baseline_meta_chain_r_clf = ClassifierChain(zero_baseline_clf, random_state=0) # random order\n",
    "zero_baseline_meta_chain_r_clf = zero_baseline_meta_chain_r_clf.fit(X_train, Y_train)\n",
    "\n",
    "for i in range(100):\n",
    "    X_test_resampled, y_test_resampled = resample(X_test, Y_test, replace=True, n_samples=len(Y_test), random_state=0+i)\n",
    "\n",
    "    y_prob = zero_baseline_meta_chain_r_clf.predict_proba(X_test_resampled)\n",
    "    y_pred = zero_baseline_meta_chain_r_clf.predict(X_test_resampled)\n",
    "\n",
    "    # Compute brier score\n",
    "    brier_scores = np.zeros(y_prob.shape[1])\n",
    "    for i in range(y_prob.shape[1]):\n",
    "        brier_scores[i] = brier_score_loss(y_test_resampled.iloc[:,i], y_prob[:,i])\n",
    "    brier_zero_basline_chain_r.append(brier_scores.mean()) \n",
    "    \n",
    "    # Other metrics\n",
    "    auprc_zero_basline_chain_r.append(average_precision_score(y_test_resampled, y_prob, average='macro')) \n",
    "    auroc_zero_basline_chain_r.append(roc_auc_score(y_test_resampled, y_prob, average='macro'))\n",
    "    f1_zero_basline_chain_r.append(f1_score(y_test_resampled, y_pred, average='micro'))\n",
    "    hamm_zero_basline_chain_r.append(hamming_loss(y_test_resampled, y_pred))\n",
    "\n",
    "print(f\"Mean scores for always zero baseline with ClassifierChain (random order) with 95% confidence intervals:\")\n",
    "print(\"    AUPRC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auprc_zero_basline_chain_r), np.percentile(auprc_zero_basline_chain_r, 2.5), np.percentile(auprc_zero_basline_chain_r, 97.5)))\n",
    "print(\"    AUROC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auroc_zero_basline_chain_r), np.percentile(auroc_zero_basline_chain_r, 2.5), np.percentile(auroc_zero_basline_chain_r, 97.5)))\n",
    "print(\"    Brier score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(brier_zero_basline_chain_r), np.percentile(brier_zero_basline_chain_r, 2.5), np.percentile(brier_zero_basline_chain_r, 97.5)))\n",
    "print(\"    Hamming loss: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(hamm_zero_basline_chain_r), np.percentile(hamm_zero_basline_chain_r, 2.5), np.percentile(hamm_zero_basline_chain_r, 97.5)))\n",
    "print(\"    Micro Avg F1 score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(f1_zero_basline_chain_r), np.percentile(f1_zero_basline_chain_r, 2.5), np.percentile(f1_zero_basline_chain_r, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Label proportion baseline estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores for label proportion baseline with ClassifierChain (random order) with 95% confidence intervals:\n",
      "    AUPRC macro: 0.17 [0.16, 0.18]\n",
      "    AUROC macro: 0.50 [0.50, 0.50]\n",
      "    Brier score: 0.17 [0.16, 0.18]\n",
      "    Hamming loss: 0.17 [0.16, 0.18]\n",
      "    Micro Avg F1 score: 0.00 [0.00, 0.00]\n"
     ]
    }
   ],
   "source": [
    "auprc_lprop_basline_chain = []\n",
    "auroc_lprop_basline_chain = []\n",
    "brier_lprop_basline_chain = []\n",
    "f1_lprop_basline_chain = []\n",
    "hamm_lprop_basline_chain = []\n",
    "\n",
    "lprop_baseline_clf = DummyClassifier(strategy='prior', random_state=0)\n",
    "lprop_baseline_meta_chain_clf = ClassifierChain(zero_baseline_clf, random_state=0) # random order\n",
    "lprop_baseline_meta_chain_clf = lprop_baseline_meta_chain_clf.fit(X_train, Y_train)\n",
    "\n",
    "for i in range(100):\n",
    "    X_test_resampled, y_test_resampled = resample(X_test, Y_test, replace=True, n_samples=len(Y_test), random_state=0+i)\n",
    "    \n",
    "\n",
    "    y_prob = lprop_baseline_meta_chain_clf.predict_proba(X_test_resampled)\n",
    "    y_pred = lprop_baseline_meta_chain_clf.predict(X_test_resampled)\n",
    "\n",
    "    # Compute brier score\n",
    "    brier_scores = np.zeros(y_prob.shape[1])\n",
    "    for i in range(y_prob.shape[1]):\n",
    "        brier_scores[i] = brier_score_loss(y_test_resampled.iloc[:,i], y_prob[:,i])\n",
    "    brier_lprop_basline_chain.append(brier_scores.mean()) \n",
    "    \n",
    "    # Other metrics\n",
    "    auprc_lprop_basline_chain.append(average_precision_score(y_test_resampled, y_prob, average='macro')) \n",
    "    auroc_lprop_basline_chain.append(roc_auc_score(y_test_resampled, y_prob, average='macro'))\n",
    "    f1_lprop_basline_chain.append(f1_score(y_test_resampled, y_pred, average='micro'))\n",
    "    hamm_lprop_basline_chain.append(hamming_loss(y_test_resampled, y_pred))\n",
    "\n",
    "print(f\"Mean scores for label proportion baseline with ClassifierChain (random order) with 95% confidence intervals:\")\n",
    "print(\"    AUPRC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auprc_lprop_basline_chain), np.percentile(auprc_lprop_basline_chain, 2.5), np.percentile(auprc_lprop_basline_chain, 97.5)))\n",
    "print(\"    AUROC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auroc_lprop_basline_chain), np.percentile(auroc_lprop_basline_chain, 2.5), np.percentile(auroc_lprop_basline_chain, 97.5)))\n",
    "print(\"    Brier score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(brier_lprop_basline_chain), np.percentile(brier_lprop_basline_chain, 2.5), np.percentile(brier_lprop_basline_chain, 97.5)))\n",
    "print(\"    Hamming loss: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(hamm_lprop_basline_chain), np.percentile(hamm_lprop_basline_chain, 2.5), np.percentile(hamm_lprop_basline_chain, 97.5)))\n",
    "print(\"    Micro Avg F1 score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(f1_lprop_basline_chain), np.percentile(f1_lprop_basline_chain, 2.5), np.percentile(f1_lprop_basline_chain, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores for LR with ClassifierChain (random order) with 95% confidence intervals:\n",
      "    AUPRC macro: 0.20 [0.19, 0.22]\n",
      "    AUROC macro: 0.55 [0.53, 0.57]\n",
      "    Brier score: 0.23 [0.22, 0.24]\n",
      "    Hamming loss: 0.28 [0.27, 0.29]\n",
      "    Micro Avg F1 score: 0.35 [0.33, 0.36]\n"
     ]
    }
   ],
   "source": [
    "auprc_LR_meta_chain_r = []\n",
    "auroc_LR_meta_chain_r = []\n",
    "brier_LR_meta_chain_r = []\n",
    "f1_LR_meta_chain_r = []\n",
    "hamm_LR_meta_chain_r = []\n",
    "\n",
    "LR_base_clf = LogisticRegression(class_weight='balanced', max_iter=10000, random_state=0, n_jobs=-1)\n",
    "LR_meta_chain_r_clf = ClassifierChain(LR_base_clf, random_state=0) # random order\n",
    "LR_meta_chain_r_clf = LR_meta_chain_r_clf.fit(X_train, Y_train)\n",
    "\n",
    "for i in range(100):\n",
    "    X_test_resampled, y_test_resampled = resample(X_test, Y_test, replace=True, n_samples=len(Y_test), random_state=0+i)\n",
    "\n",
    "    Y_prob = LR_meta_chain_r_clf.predict_proba(X_test_resampled)\n",
    "    Y_pred = LR_meta_chain_r_clf.predict(X_test_resampled)\n",
    "    \n",
    "    # Compute brier score\n",
    "    brier_scores = np.zeros(Y_prob.shape[1])\n",
    "    for i in range(Y_prob.shape[1]):\n",
    "        brier_scores[i] = brier_score_loss(y_test_resampled.iloc[:,i], Y_prob[:, i])\n",
    "    brier_LR_meta_chain_r.append(brier_scores.mean())\n",
    "\n",
    "    # Other metrics\n",
    "    auprc_LR_meta_chain_r.append(average_precision_score(y_test_resampled, Y_prob, average='macro')) \n",
    "    auroc_LR_meta_chain_r.append(roc_auc_score(y_test_resampled, Y_prob, average='macro'))\n",
    "    f1_LR_meta_chain_r.append(f1_score(y_test_resampled, Y_pred, average='micro'))\n",
    "    hamm_LR_meta_chain_r.append(hamming_loss(y_test_resampled, Y_pred))\n",
    "\n",
    "\n",
    "print(f\"Mean scores for LR with ClassifierChain (random order) with 95% confidence intervals:\")\n",
    "print(\"    AUPRC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auprc_LR_meta_chain_r), np.percentile(auprc_LR_meta_chain_r, 2.5), np.percentile(auprc_LR_meta_chain_r, 97.5)))\n",
    "print(\"    AUROC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auroc_LR_meta_chain_r), np.percentile(auroc_LR_meta_chain_r, 2.5), np.percentile(auroc_LR_meta_chain_r, 97.5)))\n",
    "print(\"    Brier score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(brier_LR_meta_chain_r), np.percentile(brier_LR_meta_chain_r, 2.5), np.percentile(brier_LR_meta_chain_r, 97.5)))\n",
    "print(\"    Hamming loss: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(hamm_LR_meta_chain_r), np.percentile(hamm_LR_meta_chain_r, 2.5), np.percentile(hamm_LR_meta_chain_r, 97.5)))\n",
    "print(\"    Micro Avg F1 score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(f1_LR_meta_chain_r), np.percentile(f1_LR_meta_chain_r, 2.5), np.percentile(f1_LR_meta_chain_r, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores for SVM with ClassifierChain (random order) with 95% confidence intervals:\n",
      "    AUPRC macro: 0.20 [0.20, 0.21]\n",
      "    AUROC macro: 0.55 [0.53, 0.56]\n",
      "    Brier score: 0.23 [0.22, 0.23]\n",
      "    Hamming loss: 0.28 [0.27, 0.28]\n",
      "    Micro Avg F1 score: 0.34 [0.33, 0.35]\n"
     ]
    }
   ],
   "source": [
    "auprc_SVM_meta_chain_r = []\n",
    "auroc_SVM_meta_chain_r = []\n",
    "brier_SVM_meta_chain_r = []\n",
    "f1_SVM_meta_chain_r = []\n",
    "hamm_SVM_meta_chain_r = []\n",
    "\n",
    "SVC_base_clf = SVC(class_weight='balanced', kernel='rbf', gamma='scale', probability=True, random_state=0)\n",
    "SVC_meta_chain_r_clf = ClassifierChain(SVC_base_clf, random_state=0) # random order\n",
    "SVC_meta_chain_r_clf = LR_meta_chain_r_clf.fit(X_train, Y_train)\n",
    "\n",
    "for i in range(10):\n",
    "    X_test_resampled, y_test_resampled = resample(X_test, Y_test, replace=True, n_samples=len(Y_test), random_state=0+i)\n",
    "\n",
    "    Y_prob = SVC_meta_chain_r_clf.predict_proba(X_test_resampled)\n",
    "    Y_pred = SVC_meta_chain_r_clf.predict(X_test_resampled)\n",
    "    \n",
    "    # Compute brier score\n",
    "    brier_scores = np.zeros(Y_prob.shape[1])\n",
    "    for i in range(Y_prob.shape[1]):\n",
    "        brier_scores[i] = brier_score_loss(y_test_resampled.iloc[:,i], Y_prob[:, i])\n",
    "    brier_SVM_meta_chain_r.append(brier_scores.mean())\n",
    "\n",
    "    # Other metrics\n",
    "    auprc_SVM_meta_chain_r.append(average_precision_score(y_test_resampled, Y_prob, average='macro')) \n",
    "    auroc_SVM_meta_chain_r.append(roc_auc_score(y_test_resampled, Y_prob, average='macro'))\n",
    "    f1_SVM_meta_chain_r.append(f1_score(y_test_resampled, Y_pred, average='micro'))\n",
    "    hamm_SVM_meta_chain_r.append(hamming_loss(y_test_resampled, Y_pred))\n",
    "\n",
    "\n",
    "print(f\"Mean scores for SVM with ClassifierChain (random order) with 95% confidence intervals:\")\n",
    "print(\"    AUPRC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auprc_SVM_meta_chain_r), np.percentile(auprc_SVM_meta_chain_r, 2.5), np.percentile(auprc_SVM_meta_chain_r, 97.5)))\n",
    "print(\"    AUROC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auroc_SVM_meta_chain_r), np.percentile(auroc_SVM_meta_chain_r, 2.5), np.percentile(auroc_SVM_meta_chain_r, 97.5)))\n",
    "print(\"    Brier score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(brier_SVM_meta_chain_r), np.percentile(brier_SVM_meta_chain_r, 2.5), np.percentile(brier_SVM_meta_chain_r, 97.5)))\n",
    "print(\"    Hamming loss: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(hamm_SVM_meta_chain_r), np.percentile(hamm_SVM_meta_chain_r, 2.5), np.percentile(hamm_SVM_meta_chain_r, 97.5)))\n",
    "print(\"    Micro Avg F1 score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(f1_SVM_meta_chain_r), np.percentile(f1_SVM_meta_chain_r, 2.5), np.percentile(f1_SVM_meta_chain_r, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores for RF meta with ClassifierChain (random order) with 95% confidence intervals:\n",
      "    AUPRC macro: 0.20 [0.19, 0.22]\n",
      "    AUROC macro: 0.55 [0.53, 0.57]\n",
      "    Brier score: 0.23 [0.22, 0.24]\n",
      "    Hamming loss: 0.28 [0.27, 0.29]\n",
      "    Micro Avg F1 score: 0.35 [0.33, 0.36]\n"
     ]
    }
   ],
   "source": [
    "auprc_RF_meta_chain_r = []\n",
    "auroc_RF_meta_chain_r = []\n",
    "brier_RF_meta_chain_r = []\n",
    "f1_RF_meta_chain_r = []\n",
    "hamm_RF_meta_chain_r = []\n",
    "\n",
    "RF_base_clf = RandomForestClassifier(n_jobs=-1, random_state=0)\n",
    "RF_meta_chain_r_clf = ClassifierChain(RF_base_clf, random_state=0) # random order\n",
    "RF_meta_chain_r_clf = LR_meta_chain_r_clf.fit(X_train, Y_train)\n",
    "\n",
    "for i in range(100):\n",
    "    X_test_resampled, y_test_resampled = resample(X_test, Y_test, replace=True, n_samples=len(Y_test), random_state=0+i)\n",
    "\n",
    "    Y_prob = RF_meta_chain_r_clf.predict_proba(X_test_resampled)\n",
    "    Y_pred = RF_meta_chain_r_clf.predict(X_test_resampled)\n",
    "    \n",
    "    # Compute brier score\n",
    "    brier_scores = np.zeros(Y_prob.shape[1])\n",
    "    for i in range(Y_prob.shape[1]):\n",
    "        brier_scores[i] = brier_score_loss(y_test_resampled.iloc[:,i], Y_prob[:, i])\n",
    "    brier_RF_meta_chain_r.append(brier_scores.mean())\n",
    "\n",
    "    # Other metrics\n",
    "    auprc_RF_meta_chain_r.append(average_precision_score(y_test_resampled, Y_prob, average='macro')) \n",
    "    auroc_RF_meta_chain_r.append(roc_auc_score(y_test_resampled, Y_prob, average='macro'))\n",
    "    f1_RF_meta_chain_r.append(f1_score(y_test_resampled, Y_pred, average='micro'))\n",
    "    hamm_RF_meta_chain_r.append(hamming_loss(y_test_resampled, Y_pred))\n",
    "\n",
    "\n",
    "print(f\"Mean scores for RF meta with ClassifierChain (random order) with 95% confidence intervals:\")\n",
    "print(\"    AUPRC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auprc_RF_meta_chain_r), np.percentile(auprc_RF_meta_chain_r, 2.5), np.percentile(auprc_RF_meta_chain_r, 97.5)))\n",
    "print(\"    AUROC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auroc_RF_meta_chain_r), np.percentile(auroc_RF_meta_chain_r, 2.5), np.percentile(auroc_RF_meta_chain_r, 97.5)))\n",
    "print(\"    Brier score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(brier_RF_meta_chain_r), np.percentile(brier_RF_meta_chain_r, 2.5), np.percentile(brier_RF_meta_chain_r, 97.5)))\n",
    "print(\"    Hamming loss: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(hamm_RF_meta_chain_r), np.percentile(hamm_RF_meta_chain_r, 2.5), np.percentile(hamm_RF_meta_chain_r, 97.5)))\n",
    "print(\"    Micro Avg F1 score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(f1_RF_meta_chain_r), np.percentile(f1_RF_meta_chain_r, 2.5), np.percentile(f1_RF_meta_chain_r, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Histogram-based Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores for HGB with ClassifierChain (random order) with 95% confidence intervals:\n",
      "    AUPRC macro: 0.21 [0.20, 0.23]\n",
      "    AUROC macro: 0.59 [0.57, 0.60]\n",
      "    Brier score: 0.13 [0.12, 0.13]\n",
      "    Hamming loss: 0.15 [0.15, 0.16]\n",
      "    Micro Avg F1 score: 0.38 [0.35, 0.39]\n"
     ]
    }
   ],
   "source": [
    "auprc_HGB_meta_chain_r = []\n",
    "auroc_HGB_meta_chain_r = []\n",
    "brier_HGB_meta_chain_r = []\n",
    "f1_HGB_meta_chain_r = []\n",
    "hamm_HGB_meta_chain_r = []\n",
    "\n",
    "\n",
    "HGB_base_clf = HistGradientBoostingClassifier(random_state=0)\n",
    "HGB_meta_chain_r_clf = ClassifierChain(HGB_base_clf, random_state=0) # random order\n",
    "HGB_meta_chain_r_clf = HGB_meta_chain_r_clf.fit(X_train, Y_train)\n",
    "\n",
    "for i in range(10):\n",
    "    X_test_resampled, y_test_resampled = resample(X_test, Y_test, replace=True, n_samples=len(Y_test), random_state=0+i)\n",
    "\n",
    "    Y_prob = HGB_meta_chain_r_clf.predict_proba(X_test_resampled)\n",
    "    Y_pred = HGB_meta_chain_r_clf.predict(X_test_resampled)\n",
    "    \n",
    "    # Compute brier score\n",
    "    brier_scores = np.zeros(Y_prob.shape[1])\n",
    "    for i in range(Y_prob.shape[1]):\n",
    "        brier_scores[i] = brier_score_loss(y_test_resampled.iloc[:,i], Y_prob[:, i])\n",
    "    brier_HGB_meta_chain_r.append(brier_scores.mean())\n",
    "\n",
    "    # Other metrics\n",
    "    auprc_HGB_meta_chain_r.append(average_precision_score(y_test_resampled, Y_prob, average='macro')) \n",
    "    auroc_HGB_meta_chain_r.append(roc_auc_score(y_test_resampled, Y_prob, average='macro'))\n",
    "    f1_HGB_meta_chain_r.append(f1_score(y_test_resampled, Y_pred, average='micro'))\n",
    "    hamm_HGB_meta_chain_r.append(hamming_loss(y_test_resampled, Y_pred))\n",
    "\n",
    "print(f\"Mean scores for HGB with ClassifierChain (random order) with 95% confidence intervals:\")\n",
    "print(\"    AUPRC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auprc_HGB_meta_chain_r), np.percentile(auprc_HGB_meta_chain_r, 2.5), np.percentile(auprc_HGB_meta_chain_r, 97.5)))\n",
    "print(\"    AUROC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auroc_HGB_meta_chain_r), np.percentile(auroc_HGB_meta_chain_r, 2.5), np.percentile(auroc_HGB_meta_chain_r, 97.5)))\n",
    "print(\"    Brier score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(brier_HGB_meta_chain_r), np.percentile(brier_HGB_meta_chain_r, 2.5), np.percentile(brier_HGB_meta_chain_r, 97.5)))\n",
    "print(\"    Hamming loss: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(hamm_HGB_meta_chain_r), np.percentile(hamm_HGB_meta_chain_r, 2.5), np.percentile(hamm_HGB_meta_chain_r, 97.5)))\n",
    "print(\"    Micro Avg F1 score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(f1_HGB_meta_chain_r), np.percentile(f1_HGB_meta_chain_r, 2.5), np.percentile(f1_HGB_meta_chain_r, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7. MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores for MLP with ClassifierChain (random order) with 95% confidence intervals:\n",
      "    AUPRC macro: 0.21 [0.20, 0.23]\n",
      "    AUROC macro: 0.58 [0.55, 0.60]\n",
      "    Brier score: 0.16 [0.15, 0.17]\n",
      "    Hamming loss: 0.19 [0.18, 0.20]\n",
      "    Micro Avg F1 score: 0.37 [0.35, 0.39]\n"
     ]
    }
   ],
   "source": [
    "auprc_MLP_meta_chain_r = []\n",
    "auroc_MLP_meta_chain_r = []\n",
    "brier_MLP_meta_chain_r = []\n",
    "f1_MLP_meta_chain_r = []\n",
    "hamm_MLP_meta_chain_r = []\n",
    "\n",
    "MLP_base_clf = MLPClassifier(random_state=0)\n",
    "MLP_meta_chain_r_clf = ClassifierChain(MLP_base_clf, random_state=0) # random order\n",
    "MLP_meta_chain_r_clf = MLP_meta_chain_r_clf.fit(X_train, Y_train)\n",
    "\n",
    "for i in range(100):\n",
    "    X_test_resampled, y_test_resampled = resample(X_test, Y_test, replace=True, n_samples=len(Y_test), random_state=0+i)\n",
    "\n",
    "    Y_prob = MLP_meta_chain_r_clf.predict_proba(X_test_resampled)\n",
    "    Y_pred = MLP_meta_chain_r_clf.predict(X_test_resampled)\n",
    "\n",
    "    # Compute brier score\n",
    "    brier_scores = np.zeros(Y_prob.shape[1])\n",
    "    for i in range(Y_prob.shape[1]):\n",
    "        brier_scores[i] = brier_score_loss(y_test_resampled.iloc[:,i], Y_prob[:, i])\n",
    "    brier_MLP_meta_chain_r.append(brier_scores.mean())\n",
    "\n",
    "    # Other metrics\n",
    "    auprc_MLP_meta_chain_r.append(average_precision_score(y_test_resampled, Y_prob, average='macro')) \n",
    "    auroc_MLP_meta_chain_r.append(roc_auc_score(y_test_resampled, Y_prob, average='macro'))\n",
    "    f1_MLP_meta_chain_r.append(f1_score(y_test_resampled, Y_pred, average='micro'))\n",
    "    hamm_MLP_meta_chain_r.append(hamming_loss(y_test_resampled, Y_pred))\n",
    "\n",
    "print(f\"Mean scores for MLP with ClassifierChain (random order) with 95% confidence intervals:\")\n",
    "print(\"    AUPRC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auprc_MLP_meta_chain_r), np.percentile(auprc_MLP_meta_chain_r, 2.5), np.percentile(auprc_MLP_meta_chain_r, 97.5)))\n",
    "print(\"    AUROC macro: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(auroc_MLP_meta_chain_r), np.percentile(auroc_MLP_meta_chain_r, 2.5), np.percentile(auroc_MLP_meta_chain_r, 97.5)))\n",
    "print(\"    Brier score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(brier_MLP_meta_chain_r), np.percentile(brier_MLP_meta_chain_r, 2.5), np.percentile(brier_MLP_meta_chain_r, 97.5)))\n",
    "print(\"    Hamming loss: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(hamm_MLP_meta_chain_r), np.percentile(hamm_MLP_meta_chain_r, 2.5), np.percentile(hamm_MLP_meta_chain_r, 97.5)))\n",
    "print(\"    Micro Avg F1 score: {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(f1_MLP_meta_chain_r), np.percentile(f1_MLP_meta_chain_r, 2.5), np.percentile(f1_MLP_meta_chain_r, 97.5)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
