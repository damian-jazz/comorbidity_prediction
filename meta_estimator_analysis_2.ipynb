{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.utils import load_data, remove_zero_features, load_confounders, standardize, label_freq_sorted, pca_transform\n",
    "from utils.utils import generate_oversampled_set, generate_undersampled_set, generate_label_stats\n",
    "from utils.utils import compute_scores\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier, ClassifierChain\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of physical cores: 8\n"
     ]
    }
   ],
   "source": [
    "N_CORES = joblib.cpu_count(only_physical_cores=True)\n",
    "print(f\"Number of physical cores: {N_CORES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for classification task\n",
    "subject_data, features, diagnoses = load_data('classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove zero features\n",
    "F = remove_zero_features(features.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load confounders\n",
    "C = load_confounders(subject_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 2815\n",
      "Number of features: 922\n"
     ]
    }
   ],
   "source": [
    "# Standardize\n",
    "X = standardize(F)\n",
    "print(f\"Number of samples: {X.shape[0]}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 13\n"
     ]
    }
   ],
   "source": [
    "# Remove ID column\n",
    "Y = diagnoses.iloc[:,1:]\n",
    "print(f\"Number of labels: {Y.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_iter = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Use undersampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_under, Y_under = generate_undersampled_set(X, Y)\n",
    "label_stats, mean_ir = generate_label_stats(Y_under, True)\n",
    "print(f\"Mean imbalance ratio: {mean_ir}\")\n",
    "label_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test (holdout) set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_under, Y_under, test_size=0.25, random_state=0)\n",
    "\n",
    "# Confounder \n",
    "C_train, C_test = C.loc[X_train.index], C.loc[X_test.index]\n",
    "\n",
    "# PCA features\n",
    "X_pca = pca_transform(F)\n",
    "X_pca_train, X_pca_test = X_pca.loc[X_train.index], X_pca.loc[X_test.index]\n",
    "\n",
    "print(f\"Number of samples in training set: {len(X_train)}\")\n",
    "print(f\"Number of samples in test set: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. MultiOutputClassifier\n",
    "Evaluate classification models wrapped in meta estimator MultiOutputClassifier with respect to multi-label performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. Dummy estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1.1. Always zero baseline estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores with SE and 95% confidence intervals:\n",
      "\n",
      "auprc_macro:                  0.10 (0.01) [0.09, 0.11]\n",
      "auprc_weighted:               0.13 (0.01) [0.11, 0.15]\n",
      "auroc_macro:                  0.50 (0.00) [0.50, 0.50]\n",
      "auroc_weighted:               0.50 (0.00) [0.50, 0.50]\n",
      "brier_macro:                  0.10 (0.01) [0.09, 0.11]\n",
      "brier_weighted:               0.01 (0.00) [0.01, 0.01]\n",
      "balanced_accuracy_macro:      0.50 (0.00) [0.50, 0.50]\n",
      "balanced_accuracy_weighted:   0.05 (0.00) [0.05, 0.05]\n",
      "f1_micro:                     0.00 (0.00) [0.00, 0.00]\n",
      "hamming:                      0.10 (0.01) [0.09, 0.11]\n",
      "subset_accuracy:              0.34 (0.03) [0.28, 0.41]\n"
     ]
    }
   ],
   "source": [
    "clf = DummyClassifier(strategy='constant', constant=0 ,random_state=0)\n",
    "meta_clf = MultiOutputClassifier(clf).fit(X_train, Y_train)\n",
    "compute_scores(meta_clf, X_test, Y_test, boot_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1.2. Label proportion baseline estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores with SE and 95% confidence intervals:\n",
      "\n",
      "auprc_macro:                  0.10 (0.01) [0.09, 0.11]\n",
      "auprc_weighted:               0.13 (0.01) [0.11, 0.15]\n",
      "auroc_macro:                  0.50 (0.00) [0.50, 0.50]\n",
      "auroc_weighted:               0.50 (0.00) [0.50, 0.50]\n",
      "brier_macro:                  0.09 (0.00) [0.08, 0.10]\n",
      "brier_weighted:               0.01 (0.00) [0.01, 0.01]\n",
      "balanced_accuracy_macro:      0.50 (0.00) [0.50, 0.50]\n",
      "balanced_accuracy_weighted:   0.05 (0.00) [0.05, 0.05]\n",
      "f1_micro:                     0.00 (0.00) [0.00, 0.00]\n",
      "hamming:                      0.10 (0.01) [0.09, 0.11]\n",
      "subset_accuracy:              0.34 (0.03) [0.28, 0.41]\n"
     ]
    }
   ],
   "source": [
    "clf = DummyClassifier(strategy='prior', random_state=0)\n",
    "meta_clf = MultiOutputClassifier(clf).fit(X_train, Y_train)\n",
    "compute_scores(meta_clf, X_test, Y_test, boot_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. Confounders as features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1.1. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores with SE and 95% confidence intervals:\n",
      "\n",
      "auprc_macro:                  0.14 (0.01) [0.12, 0.17]\n",
      "auprc_weighted:               0.18 (0.02) [0.15, 0.22]\n",
      "auroc_macro:                  0.53 (0.02) [0.49, 0.56]\n",
      "auroc_weighted:               0.54 (0.02) [0.51, 0.58]\n",
      "brier_macro:                  0.09 (0.00) [0.08, 0.10]\n",
      "brier_weighted:               0.01 (0.00) [0.01, 0.01]\n",
      "balanced_accuracy_macro:      0.50 (0.00) [0.50, 0.50]\n",
      "balanced_accuracy_weighted:   0.05 (0.00) [0.05, 0.05]\n",
      "f1_micro:                     0.00 (0.00) [0.00, 0.00]\n",
      "hamming:                      0.10 (0.01) [0.09, 0.11]\n",
      "subset_accuracy:              0.34 (0.03) [0.28, 0.41]\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=10000, random_state=0)\n",
    "meta_clf = MultiOutputClassifier(clf).fit(C_train, Y_train)\n",
    "compute_scores(meta_clf, C_test, Y_test, boot_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1.1. Histogram-based Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores with SE and 95% confidence intervals:\n",
      "\n",
      "auprc_macro:                  0.13 (0.01) [0.11, 0.16]\n",
      "auprc_weighted:               0.17 (0.02) [0.13, 0.21]\n",
      "auroc_macro:                  0.50 (0.02) [0.47, 0.53]\n",
      "auroc_weighted:               0.52 (0.02) [0.48, 0.56]\n",
      "brier_macro:                  0.11 (0.01) [0.10, 0.12]\n",
      "brier_weighted:               0.01 (0.00) [0.01, 0.01]\n",
      "balanced_accuracy_macro:      0.50 (0.00) [0.49, 0.51]\n",
      "balanced_accuracy_weighted:   0.05 (0.00) [0.05, 0.05]\n",
      "f1_micro:                     0.09 (0.02) [0.06, 0.12]\n",
      "hamming:                      0.13 (0.01) [0.11, 0.14]\n",
      "subset_accuracy:              0.20 (0.02) [0.17, 0.25]\n"
     ]
    }
   ],
   "source": [
    "clf = HistGradientBoostingClassifier(random_state=0)\n",
    "meta_clf = MultiOutputClassifier(clf, n_jobs=-1).fit(C_train,Y_train)\n",
    "compute_scores(meta_clf, C_test, Y_test, boot_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3. PCA-projected data (top-10 components) as features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1.1. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores with SE and 95% confidence intervals:\n",
      "\n",
      "auprc_macro:                  0.16 (0.02) [0.13, 0.19]\n",
      "auprc_weighted:               0.19 (0.02) [0.16, 0.23]\n",
      "auroc_macro:                  0.57 (0.02) [0.52, 0.62]\n",
      "auroc_weighted:               0.58 (0.02) [0.54, 0.62]\n",
      "brier_macro:                  0.09 (0.00) [0.08, 0.10]\n",
      "brier_weighted:               0.01 (0.00) [0.01, 0.01]\n",
      "balanced_accuracy_macro:      0.50 (0.00) [0.50, 0.51]\n",
      "balanced_accuracy_weighted:   0.05 (0.00) [0.05, 0.05]\n",
      "f1_micro:                     0.01 (0.01) [0.00, 0.03]\n",
      "hamming:                      0.10 (0.01) [0.09, 0.11]\n",
      "subset_accuracy:              0.34 (0.03) [0.28, 0.40]\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=10000, random_state=0)\n",
    "meta_clf = MultiOutputClassifier(clf).fit(X_pca_train, Y_train)\n",
    "compute_scores(meta_clf, X_pca_test, Y_test, boot_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1.1. Histogram-based Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores with SE and 95% confidence intervals:\n",
      "\n",
      "auprc_macro:                  0.14 (0.01) [0.12, 0.17]\n",
      "auprc_weighted:               0.17 (0.02) [0.14, 0.20]\n",
      "auroc_macro:                  0.54 (0.02) [0.49, 0.59]\n",
      "auroc_weighted:               0.54 (0.02) [0.50, 0.58]\n",
      "brier_macro:                  0.10 (0.01) [0.09, 0.11]\n",
      "brier_weighted:               0.01 (0.00) [0.01, 0.01]\n",
      "balanced_accuracy_macro:      0.50 (0.00) [0.49, 0.51]\n",
      "balanced_accuracy_weighted:   0.05 (0.00) [0.05, 0.05]\n",
      "f1_micro:                     0.08 (0.02) [0.05, 0.11]\n",
      "hamming:                      0.12 (0.01) [0.11, 0.13]\n",
      "subset_accuracy:              0.25 (0.03) [0.20, 0.30]\n"
     ]
    }
   ],
   "source": [
    "clf = HistGradientBoostingClassifier(random_state=0)\n",
    "meta_clf = MultiOutputClassifier(clf, n_jobs=-1).fit(X_pca_train,Y_train)\n",
    "compute_scores(meta_clf, X_pca_test, Y_test, boot_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4. Original features (standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4.1. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores with SE and 95% confidence intervals:\n",
      "\n",
      "auprc_macro:                  0.17 (0.01) [0.14, 0.19]\n",
      "auprc_weighted:               0.20 (0.02) [0.17, 0.24]\n",
      "auroc_macro:                  0.55 (0.02) [0.51, 0.60]\n",
      "auroc_weighted:               0.56 (0.02) [0.53, 0.59]\n",
      "brier_macro:                  0.14 (0.01) [0.13, 0.15]\n",
      "brier_weighted:               0.02 (0.00) [0.02, 0.02]\n",
      "balanced_accuracy_macro:      0.53 (0.01) [0.51, 0.55]\n",
      "balanced_accuracy_weighted:   0.05 (0.00) [0.05, 0.06]\n",
      "f1_micro:                     0.19 (0.02) [0.16, 0.22]\n",
      "hamming:                      0.17 (0.01) [0.15, 0.18]\n",
      "subset_accuracy:              0.13 (0.02) [0.10, 0.18]\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=10000, random_state=0)\n",
    "meta_clf = MultiOutputClassifier(clf).fit(X_train, Y_train)\n",
    "compute_scores(meta_clf, X_test, Y_test, boot_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4.2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores with SE and 95% confidence intervals:\n",
      "\n",
      "auprc_macro:                  0.19 (0.02) [0.15, 0.21]\n",
      "auprc_weighted:               0.23 (0.03) [0.18, 0.27]\n",
      "auroc_macro:                  0.55 (0.02) [0.51, 0.58]\n",
      "auroc_weighted:               0.55 (0.02) [0.52, 0.57]\n",
      "brier_macro:                  0.09 (0.00) [0.08, 0.09]\n",
      "brier_weighted:               0.01 (0.00) [0.01, 0.01]\n",
      "balanced_accuracy_macro:      0.50 (0.00) [0.50, 0.50]\n",
      "balanced_accuracy_weighted:   0.05 (0.00) [0.05, 0.05]\n",
      "f1_micro:                     0.00 (0.00) [0.00, 0.00]\n",
      "hamming:                      0.10 (0.00) [0.09, 0.11]\n",
      "subset_accuracy:              0.33 (0.03) [0.28, 0.37]\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', gamma='scale', probability=True, random_state=0)\n",
    "meta_clf = MultiOutputClassifier(clf, n_jobs=-1).fit(X_train, Y_train)\n",
    "compute_scores(meta_clf, X_test, Y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4.3. Histogram-based Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores with SE and 95% confidence intervals:\n",
      "\n",
      "auprc_macro:                  0.17 (0.02) [0.14, 0.20]\n",
      "auprc_weighted:               0.20 (0.02) [0.17, 0.24]\n",
      "auroc_macro:                  0.59 (0.02) [0.55, 0.63]\n",
      "auroc_weighted:               0.59 (0.02) [0.55, 0.62]\n",
      "brier_macro:                  0.10 (0.01) [0.09, 0.11]\n",
      "brier_weighted:               0.01 (0.00) [0.01, 0.01]\n",
      "balanced_accuracy_macro:      0.50 (0.00) [0.50, 0.51]\n",
      "balanced_accuracy_weighted:   0.05 (0.00) [0.05, 0.05]\n",
      "f1_micro:                     0.03 (0.01) [0.01, 0.06]\n",
      "hamming:                      0.10 (0.01) [0.09, 0.12]\n",
      "subset_accuracy:              0.32 (0.03) [0.26, 0.37]\n"
     ]
    }
   ],
   "source": [
    "clf = HistGradientBoostingClassifier(random_state=0)\n",
    "meta_clf = MultiOutputClassifier(clf, n_jobs=-1).fit(X_train, Y_train)\n",
    "compute_scores(meta_clf, X_test, Y_test, boot_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4.4. MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damianjaspar/.venv/neuro/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=0)\n",
    "meta_clf = MultiOutputClassifier(clf).fit(X_train, Y_train) #n_jobs=-1\n",
    "compute_scores(meta_clf, X_test, Y_test, boot_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. ClassifierChain (ordered by frequency) \n",
    "Evaluate classification models wrapped in meta estimator ClassifierChain with respect to multi-label performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_freq = label_freq_sorted(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores with SE and 95% confidence intervals:\n",
      "\n",
      "auprc_macro:                  0.20 (0.01) [0.18, 0.21]\n",
      "auprc_weighted:               0.30 (0.01) [0.27, 0.32]\n",
      "auroc_macro:                  0.57 (0.01) [0.54, 0.59]\n",
      "auroc_weighted:               0.55 (0.01) [0.53, 0.58]\n",
      "brier_macro:                  0.18 (0.00) [0.17, 0.19]\n",
      "brier_weighted:               0.04 (0.00) [0.04, 0.04]\n",
      "balanced_accuracy_macro:      0.52 (0.01) [0.51, 0.54]\n",
      "balanced_accuracy_weighted:   0.08 (0.00) [0.08, 0.08]\n",
      "f1_micro:                     0.29 (0.01) [0.27, 0.32]\n",
      "hamming:                      0.21 (0.01) [0.20, 0.22]\n",
      "subset_accuracy:              0.06 (0.01) [0.04, 0.07]\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=10000, random_state=0)\n",
    "meta_clf = ClassifierChain(clf, order=by_freq, random_state=0).fit(X_train, Y_train)\n",
    "compute_scores(meta_clf, X_test, Y_test, boot_iter, chain=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Histogram-based Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores with SE and 95% confidence intervals:\n",
      "\n",
      "auprc_macro:                  0.23 (0.01) [0.21, 0.25]\n",
      "auprc_weighted:               0.33 (0.01) [0.30, 0.36]\n",
      "auroc_macro:                  0.61 (0.01) [0.59, 0.64]\n",
      "auroc_weighted:               0.60 (0.01) [0.57, 0.62]\n",
      "brier_macro:                  0.13 (0.00) [0.12, 0.13]\n",
      "brier_weighted:               0.03 (0.00) [0.03, 0.03]\n",
      "balanced_accuracy_macro:      0.52 (0.00) [0.51, 0.52]\n",
      "balanced_accuracy_weighted:   0.08 (0.00) [0.08, 0.08]\n",
      "f1_micro:                     0.20 (0.01) [0.17, 0.23]\n",
      "hamming:                      0.15 (0.00) [0.15, 0.16]\n",
      "subset_accuracy:              0.11 (0.01) [0.09, 0.14]\n"
     ]
    }
   ],
   "source": [
    "clf = HistGradientBoostingClassifier(random_state=0)\n",
    "meta_clf = ClassifierChain(clf, order=by_freq, random_state=0).fit(X_train, Y_train)\n",
    "compute_scores(meta_clf, X_test, Y_test, boot_iter, chain=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. ClassifierChain (random order) \n",
    "Evaluate classification models wrapped in meta estimator ClassifierChain with respect to multi-label performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores with SE and 95% confidence intervals:\n",
      "\n",
      "auprc_macro:                  0.19 (0.01) [0.18, 0.21]\n",
      "auprc_weighted:               0.29 (0.01) [0.27, 0.32]\n",
      "auroc_macro:                  0.56 (0.01) [0.54, 0.58]\n",
      "auroc_weighted:               0.55 (0.01) [0.53, 0.57]\n",
      "brier_macro:                  0.18 (0.00) [0.17, 0.19]\n",
      "brier_weighted:               0.04 (0.00) [0.04, 0.04]\n",
      "balanced_accuracy_macro:      0.52 (0.01) [0.51, 0.54]\n",
      "balanced_accuracy_weighted:   0.08 (0.00) [0.08, 0.08]\n",
      "f1_micro:                     0.28 (0.01) [0.26, 0.31]\n",
      "hamming:                      0.21 (0.01) [0.21, 0.22]\n",
      "subset_accuracy:              0.05 (0.01) [0.03, 0.07]\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=10000, random_state=0)\n",
    "meta_clf = ClassifierChain(clf, random_state=0).fit(X_train, Y_train)\n",
    "compute_scores(meta_clf, X_test, Y_test, boot_iter, chain=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2. Histogram-based Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores with SE and 95% confidence intervals:\n",
      "\n",
      "auprc_macro:                  0.23 (0.01) [0.21, 0.25]\n",
      "auprc_weighted:               0.33 (0.01) [0.30, 0.35]\n",
      "auroc_macro:                  0.61 (0.01) [0.59, 0.63]\n",
      "auroc_weighted:               0.60 (0.01) [0.58, 0.62]\n",
      "brier_macro:                  0.13 (0.00) [0.12, 0.13]\n",
      "brier_weighted:               0.03 (0.00) [0.03, 0.03]\n",
      "balanced_accuracy_macro:      0.51 (0.00) [0.51, 0.52]\n",
      "balanced_accuracy_weighted:   0.08 (0.00) [0.08, 0.08]\n",
      "f1_micro:                     0.19 (0.01) [0.17, 0.22]\n",
      "hamming:                      0.15 (0.00) [0.15, 0.16]\n",
      "subset_accuracy:              0.11 (0.01) [0.09, 0.14]\n"
     ]
    }
   ],
   "source": [
    "clf = HistGradientBoostingClassifier(random_state=0)\n",
    "meta_clf = ClassifierChain(clf, random_state=0).fit(X_train, Y_train)\n",
    "compute_scores(meta_clf, X_test, Y_test, boot_iter, chain=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
