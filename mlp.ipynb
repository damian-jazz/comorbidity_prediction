{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.utils import load_data, remove_zero_features, standardize\n",
    "from utils.utils import generate_oversampled_set, generate_undersampled_set, generate_label_stats\n",
    "\n",
    "from utils.mlp_utils import DatasetBrainMeasures\n",
    "from utils.mlp_train import train, test, train_focal, test_focal, compute_scores\n",
    "from utils.mlp_model import MLP\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_path = \"plots/\"\n",
    "checkpoints_path = \"checkpoints/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for classification task\n",
    "subject_data, features, diagnoses = load_data('classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove zero features\n",
    "F = remove_zero_features(features.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 2815\n",
      "Number of features: 922\n"
     ]
    }
   ],
   "source": [
    "# Standardize\n",
    "X = standardize(F)\n",
    "print(f\"Number of samples: {X.shape[0]}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 13\n"
     ]
    }
   ],
   "source": [
    "# Remove ID column\n",
    "Y = diagnoses.iloc[:,1:]\n",
    "print(f\"Number of labels: {Y.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_iter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Use dataset with original label distribution (no resampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training set: 2111\n",
      "Number of samples in test set: 704\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into train and test (holdout) set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=0)\n",
    "print(f\"Number of samples in training set: {len(X_train)}\")\n",
    "print(f\"Number of samples in test set: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 2111\n",
      "Size of test set: 704\n"
     ]
    }
   ],
   "source": [
    "training_data = DatasetBrainMeasures(X_train, Y_train) \n",
    "test_data = DatasetBrainMeasures(X_test, Y_test)\n",
    "print(f\"Size of training set: {len(training_data)}\")\n",
    "print(f\"Size of test set: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [batch_size, D]: torch.Size([128, 922])\n",
      "Shape of Y [batch_size]: torch.Size([128, 13]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "for X_, y_ in test_dataloader:\n",
    "    print(f\"Shape of X [batch_size, D]: {X_.shape}\")\n",
    "    print(f\"Shape of Y [batch_size]: {y_.shape} {y_.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. BCE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(input_dim=X_train.shape[1], output_dim=Y_train.shape[1]).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.542596  [ 1071/ 2111]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.452492 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.482496  [ 1071/ 2111]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.403383 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.438573  [ 1071/ 2111]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.393528 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.393759  [ 1071/ 2111]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.388978 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.380422  [ 1071/ 2111]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.385814 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.388738  [ 1071/ 2111]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.384843 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.428315  [ 1071/ 2111]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.386596 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.360277  [ 1071/ 2111]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.381355 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.399074  [ 1071/ 2111]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.383784 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.366012  [ 1071/ 2111]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.382442 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, device, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, device, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores with SE and 95% confidence intervals:\n",
      "\n",
      "auprc_macro:                  0.20 (0.01) [0.19, 0.21]\n",
      "auprc_weighted:               0.34 (0.01) [0.33, 0.36]\n",
      "auroc_macro:                  0.55 (0.01) [0.52, 0.56]\n",
      "auroc_weighted:               0.54 (0.01) [0.52, 0.56]\n",
      "brier_macro:                  0.12 (0.00) [0.11, 0.12]\n",
      "brier_weighted:               0.03 (0.00) [0.03, 0.03]\n",
      "balanced_accuracy_macro:      0.50 (0.00) [0.50, 0.50]\n",
      "balanced_accuracy_weighted:   0.08 (0.00) [0.08, 0.08]\n",
      "f1_micro:                     0.38 (0.01) [0.36, 0.40]\n",
      "hamming:                      0.15 (0.00) [0.14, 0.16]\n",
      "subset_accuracy:              0.10 (0.01) [0.08, 0.12]\n"
     ]
    }
   ],
   "source": [
    "compute_scores(X_test, Y_test, device, model, batch_size, boot_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Focal loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(input_dim=X_train.shape[1], output_dim=Y_train.shape[1]).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "gamma = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.150447  [ 1071/ 2111]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.134527 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.125204  [ 1071/ 2111]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.113453 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.109538  [ 1071/ 2111]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.109520 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.109046  [ 1071/ 2111]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.103447 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.113481  [ 1071/ 2111]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.105218 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.102034  [ 1071/ 2111]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.105205 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.106109  [ 1071/ 2111]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.104344 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.108610  [ 1071/ 2111]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.103143 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.107384  [ 1071/ 2111]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.103583 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.108886  [ 1071/ 2111]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.103826 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_focal(train_dataloader, device, model, optimizer, gamma)\n",
    "    test_focal(test_dataloader, device, model, gamma)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores with SE and 95% confidence intervals:\n",
      "\n",
      "auprc_macro:                  0.19 (0.01) [0.18, 0.20]\n",
      "auprc_weighted:               0.33 (0.01) [0.31, 0.35]\n",
      "auroc_macro:                  0.53 (0.01) [0.50, 0.55]\n",
      "auroc_weighted:               0.52 (0.01) [0.51, 0.55]\n",
      "brier_macro:                  0.16 (0.00) [0.16, 0.17]\n",
      "brier_weighted:               0.03 (0.00) [0.03, 0.03]\n",
      "balanced_accuracy_macro:      0.50 (0.00) [0.50, 0.50]\n",
      "balanced_accuracy_weighted:   0.08 (0.00) [0.08, 0.08]\n",
      "f1_micro:                     0.38 (0.01) [0.36, 0.40]\n",
      "hamming:                      0.15 (0.00) [0.14, 0.16]\n",
      "subset_accuracy:              0.10 (0.01) [0.08, 0.12]\n"
     ]
    }
   ],
   "source": [
    "compute_scores(X_test, Y_test, device, model, batch_size, boot_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Use undersampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean imbalance ratio: 2.7700915195670985\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Absolute frequency</th>\n",
       "      <th>Relative frequency</th>\n",
       "      <th>Imbalance ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trauma_And_Stress_RelatedDisorders</th>\n",
       "      <td>69</td>\n",
       "      <td>0.069277</td>\n",
       "      <td>3.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DepressiveDisorders</th>\n",
       "      <td>103</td>\n",
       "      <td>0.103414</td>\n",
       "      <td>2.184466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attention_Deficit_HyperactivityDisorder</th>\n",
       "      <td>225</td>\n",
       "      <td>0.225904</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MotorDisorder</th>\n",
       "      <td>68</td>\n",
       "      <td>0.068273</td>\n",
       "      <td>3.308824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AutismSpectrumDisorder</th>\n",
       "      <td>117</td>\n",
       "      <td>0.117470</td>\n",
       "      <td>1.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CommunicationDisorder</th>\n",
       "      <td>105</td>\n",
       "      <td>0.105422</td>\n",
       "      <td>2.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OtherDisorders</th>\n",
       "      <td>55</td>\n",
       "      <td>0.055221</td>\n",
       "      <td>4.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpecificLearningDisorder</th>\n",
       "      <td>177</td>\n",
       "      <td>0.177711</td>\n",
       "      <td>1.271186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obsessive_Compulsive_And_RelatedDisorders</th>\n",
       "      <td>52</td>\n",
       "      <td>0.052209</td>\n",
       "      <td>4.326923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disruptive</th>\n",
       "      <td>103</td>\n",
       "      <td>0.103414</td>\n",
       "      <td>2.184466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IntellectualDisability</th>\n",
       "      <td>34</td>\n",
       "      <td>0.034137</td>\n",
       "      <td>6.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EliminationDisorder</th>\n",
       "      <td>89</td>\n",
       "      <td>0.089357</td>\n",
       "      <td>2.528090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnxietyDisorders</th>\n",
       "      <td>192</td>\n",
       "      <td>0.192771</td>\n",
       "      <td>1.171875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Absolute frequency  \\\n",
       "Trauma_And_Stress_RelatedDisorders                         69   \n",
       "DepressiveDisorders                                       103   \n",
       "Attention_Deficit_HyperactivityDisorder                   225   \n",
       "MotorDisorder                                              68   \n",
       "AutismSpectrumDisorder                                    117   \n",
       "CommunicationDisorder                                     105   \n",
       "OtherDisorders                                             55   \n",
       "SpecificLearningDisorder                                  177   \n",
       "Obsessive_Compulsive_And_RelatedDisorders                  52   \n",
       "Disruptive                                                103   \n",
       "IntellectualDisability                                     34   \n",
       "EliminationDisorder                                        89   \n",
       "AnxietyDisorders                                          192   \n",
       "\n",
       "                                           Relative frequency  Imbalance ratio  \n",
       "Trauma_And_Stress_RelatedDisorders                   0.069277         3.260870  \n",
       "DepressiveDisorders                                  0.103414         2.184466  \n",
       "Attention_Deficit_HyperactivityDisorder              0.225904         1.000000  \n",
       "MotorDisorder                                        0.068273         3.308824  \n",
       "AutismSpectrumDisorder                               0.117470         1.923077  \n",
       "CommunicationDisorder                                0.105422         2.142857  \n",
       "OtherDisorders                                       0.055221         4.090909  \n",
       "SpecificLearningDisorder                             0.177711         1.271186  \n",
       "Obsessive_Compulsive_And_RelatedDisorders            0.052209         4.326923  \n",
       "Disruptive                                           0.103414         2.184466  \n",
       "IntellectualDisability                               0.034137         6.617647  \n",
       "EliminationDisorder                                  0.089357         2.528090  \n",
       "AnxietyDisorders                                     0.192771         1.171875  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_under, Y_under = generate_undersampled_set(X, Y)\n",
    "label_stats, mean_ir = generate_label_stats(Y_under, True)\n",
    "print(f\"Mean imbalance ratio: {mean_ir}\")\n",
    "label_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test (holdout) set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_under, Y_under, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 747\n",
      "Size of test set: 249\n"
     ]
    }
   ],
   "source": [
    "training_data = DatasetBrainMeasures(X_train, Y_train) \n",
    "test_data = DatasetBrainMeasures(X_test, Y_test)\n",
    "print(f\"Size of training set: {len(training_data)}\")\n",
    "print(f\"Size of test set: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [batch_size, D]: torch.Size([128, 922])\n",
      "Shape of Y [batch_size]: torch.Size([128, 13]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "for X_, y_ in test_dataloader:\n",
    "    print(f\"Shape of X [batch_size, D]: {X_.shape}\")\n",
    "    print(f\"Shape of Y [batch_size]: {y_.shape} {y_.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(input_dim=X_train.shape[1], output_dim=Y_train.shape[1]).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.689463  [  642/  747]\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.673110 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.576843  [  642/  747]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.480573 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.542820  [  642/  747]\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.401111 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.473360  [  642/  747]\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.403863 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.485260  [  642/  747]\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.355795 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.432499  [  642/  747]\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.347368 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.450551  [  642/  747]\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.338777 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.401458  [  642/  747]\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.339597 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.361977  [  642/  747]\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.330575 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.394854  [  642/  747]\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.326537 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, device, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, device, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores with SE and 95% confidence intervals:\n",
      "\n",
      "auprc_macro:                  0.14 (0.01) [0.11, 0.17]\n",
      "auprc_weighted:               0.17 (0.01) [0.14, 0.20]\n",
      "auroc_macro:                  0.54 (0.02) [0.50, 0.58]\n",
      "auroc_weighted:               0.54 (0.02) [0.50, 0.58]\n",
      "brier_macro:                  0.09 (0.00) [0.08, 0.10]\n",
      "brier_weighted:               0.01 (0.00) [0.01, 0.01]\n",
      "balanced_accuracy_macro:      0.50 (0.00) [0.50, 0.50]\n",
      "balanced_accuracy_weighted:   0.05 (0.00) [0.05, 0.05]\n",
      "f1_micro:                     0.00 (0.00) [0.00, 0.00]\n",
      "hamming:                      0.10 (0.01) [0.09, 0.11]\n",
      "subset_accuracy:              0.34 (0.03) [0.28, 0.41]\n"
     ]
    }
   ],
   "source": [
    "compute_scores(X_test, Y_test, device, model, batch_size, boot_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Use oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean imbalance ratio: 1.6092872677464145\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Absolute frequency</th>\n",
       "      <th>Relative frequency</th>\n",
       "      <th>Imbalance ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trauma_And_Stress_RelatedDisorders</th>\n",
       "      <td>2580</td>\n",
       "      <td>0.116174</td>\n",
       "      <td>1.923256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DepressiveDisorders</th>\n",
       "      <td>3170</td>\n",
       "      <td>0.142741</td>\n",
       "      <td>1.565300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attention_Deficit_HyperactivityDisorder</th>\n",
       "      <td>4582</td>\n",
       "      <td>0.206322</td>\n",
       "      <td>1.082933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MotorDisorder</th>\n",
       "      <td>3134</td>\n",
       "      <td>0.141120</td>\n",
       "      <td>1.583280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AutismSpectrumDisorder</th>\n",
       "      <td>3689</td>\n",
       "      <td>0.166111</td>\n",
       "      <td>1.345080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CommunicationDisorder</th>\n",
       "      <td>4431</td>\n",
       "      <td>0.199523</td>\n",
       "      <td>1.119838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OtherDisorders</th>\n",
       "      <td>2320</td>\n",
       "      <td>0.104467</td>\n",
       "      <td>2.138793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpecificLearningDisorder</th>\n",
       "      <td>4962</td>\n",
       "      <td>0.223433</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obsessive_Compulsive_And_RelatedDisorders</th>\n",
       "      <td>2668</td>\n",
       "      <td>0.120137</td>\n",
       "      <td>1.859820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disruptive</th>\n",
       "      <td>2801</td>\n",
       "      <td>0.126126</td>\n",
       "      <td>1.771510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IntellectualDisability</th>\n",
       "      <td>2101</td>\n",
       "      <td>0.094606</td>\n",
       "      <td>2.361733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EliminationDisorder</th>\n",
       "      <td>2887</td>\n",
       "      <td>0.129998</td>\n",
       "      <td>1.718739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnxietyDisorders</th>\n",
       "      <td>3421</td>\n",
       "      <td>0.154044</td>\n",
       "      <td>1.450453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Absolute frequency  \\\n",
       "Trauma_And_Stress_RelatedDisorders                       2580   \n",
       "DepressiveDisorders                                      3170   \n",
       "Attention_Deficit_HyperactivityDisorder                  4582   \n",
       "MotorDisorder                                            3134   \n",
       "AutismSpectrumDisorder                                   3689   \n",
       "CommunicationDisorder                                    4431   \n",
       "OtherDisorders                                           2320   \n",
       "SpecificLearningDisorder                                 4962   \n",
       "Obsessive_Compulsive_And_RelatedDisorders                2668   \n",
       "Disruptive                                               2801   \n",
       "IntellectualDisability                                   2101   \n",
       "EliminationDisorder                                      2887   \n",
       "AnxietyDisorders                                         3421   \n",
       "\n",
       "                                           Relative frequency  Imbalance ratio  \n",
       "Trauma_And_Stress_RelatedDisorders                   0.116174         1.923256  \n",
       "DepressiveDisorders                                  0.142741         1.565300  \n",
       "Attention_Deficit_HyperactivityDisorder              0.206322         1.082933  \n",
       "MotorDisorder                                        0.141120         1.583280  \n",
       "AutismSpectrumDisorder                               0.166111         1.345080  \n",
       "CommunicationDisorder                                0.199523         1.119838  \n",
       "OtherDisorders                                       0.104467         2.138793  \n",
       "SpecificLearningDisorder                             0.223433         1.000000  \n",
       "Obsessive_Compulsive_And_RelatedDisorders            0.120137         1.859820  \n",
       "Disruptive                                           0.126126         1.771510  \n",
       "IntellectualDisability                               0.094606         2.361733  \n",
       "EliminationDisorder                                  0.129998         1.718739  \n",
       "AnxietyDisorders                                     0.154044         1.450453  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample data (undersampling)\n",
    "X_over, Y_over = generate_oversampled_set(X, Y)\n",
    "label_stats, mean_ir = generate_label_stats(Y_over, True)\n",
    "print(f\"Mean imbalance ratio: {mean_ir}\")\n",
    "label_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test (holdout) set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_over, Y_over, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 16656\n",
      "Size of test set: 5552\n"
     ]
    }
   ],
   "source": [
    "training_data = DatasetBrainMeasures(X_train, Y_train) \n",
    "test_data = DatasetBrainMeasures(X_test, Y_test)\n",
    "print(f\"Size of training set: {len(training_data)}\")\n",
    "print(f\"Size of test set: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [batch_size, D]: torch.Size([128, 922])\n",
      "Shape of Y [batch_size]: torch.Size([128, 13]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "for X_, y_ in test_dataloader:\n",
    "    print(f\"Shape of X [batch_size, D]: {X_.shape}\")\n",
    "    print(f\"Shape of Y [batch_size]: {y_.shape} {y_.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(input_dim=X_train.shape[1], output_dim=Y_train.shape[1]).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, device, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, device, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores with SE and 95% confidence intervals:\n",
      "\n",
      "auprc_macro:                  0.88 (0.00) [0.88, 0.89]\n",
      "auprc_weighted:               0.86 (0.00) [0.86, 0.87]\n",
      "auroc_macro:                  0.97 (0.00) [0.97, 0.97]\n",
      "auroc_weighted:               0.96 (0.00) [0.96, 0.96]\n",
      "brier_macro:                  0.04 (0.00) [0.04, 0.05]\n",
      "brier_weighted:               0.01 (0.00) [0.01, 0.01]\n",
      "balanced_accuracy_macro:      0.85 (0.00) [0.85, 0.86]\n",
      "balanced_accuracy_weighted:   0.12 (0.00) [0.12, 0.13]\n",
      "f1_micro:                     0.77 (0.00) [0.76, 0.78]\n",
      "hamming:                      0.06 (0.00) [0.06, 0.06]\n",
      "subset_accuracy:              0.56 (0.01) [0.54, 0.57]\n"
     ]
    }
   ],
   "source": [
    "compute_scores(X_test, Y_test, device, model, batch_size, boot_iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
